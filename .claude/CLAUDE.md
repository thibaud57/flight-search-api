# CLAUDE.md - flight-search-api

**Instructions de dÃ©veloppement et standards du projet**

---

## ğŸ“‹ Contexte Projet

**Nom** : flight-search-api

**Description** : API FastAPI pour recherche de vols multi-destinations via Google Flights (scraping avec Crawl4AI + proxies Decodo)

**Stack Technique** :
- Python 3.13.1+
- FastAPI 0.121.2+
- Pydantic v2.12.4+ (Settings)
- Crawl4AI 0.7.7+ (AsyncWebCrawler + Playwright intÃ©grÃ©)
- Tenacity 9.1.2+ (retry logic async)
- Decodo Proxies (rÃ©sidentiels, France targeting)

**Architecture** : API async, scraping stealth, extraction CSS (pas de LLM), Top 10 rÃ©sultats en mÃ©moire (pas de DB)

**Approche Captcha** :
- **MVP (Phase 5-6)** : DÃ©tection uniquement (logging), pas de rÃ©solution
- **Post-MVP (Phase 7 optionnel)** : 2Captcha si monitoring montre >5% blocages

---

## ğŸ Standards Python

### 1. Type Hints Modernes (PEP 695)

**Python 3.13+ supporte la syntaxe simplifiÃ©e** :

```python
# âŒ Ancienne syntaxe (< Python 3.12)
from typing import TypeVar, Generic
T = TypeVar('T')

class Response(Generic[T]):
    data: T

# âœ… Nouvelle syntaxe PEP 695 (Python 3.12+)
class Response[T]:
    data: T

# âœ… Fonctions gÃ©nÃ©riques
def process[T](items: list[T]) -> T:
    return items[0]

# âœ… Type aliases
type JsonDict = dict[str, str | int | float | bool | None]
```

**RÃ¨gles obligatoires** :
- âœ… Utiliser PEP 695 partout (classes, fonctions, type aliases)
- âœ… Annoter TOUTES les signatures de fonctions (args + return)
- âœ… Utiliser `list[T]`, `dict[K, V]` au lieu de `List[T]`, `Dict[K, V]`
- âœ… PrÃ©fÃ©rer `X | None` Ã  `Optional[X]`
- âœ… Type alias avec `type` keyword pour clartÃ©

**Contraintes** :
```python
# âœ… Bounds
class Container[T: (str, int)]:  # T doit Ãªtre str ou int
    value: T

# âœ… Upper bound
class Processor[T: BaseModel]:  # T doit hÃ©riter de BaseModel
    def process(self, item: T) -> T: ...
```

---

### 2. Ruff - Linter & Formatter

**Configuration `pyproject.toml`** :

```toml
[tool.ruff]
line-length = 88
indent-width = 4
target-version = "py313"

[tool.ruff.lint]
select = [
    "E",      # pycodestyle errors
    "F",      # pyflakes
    "I",      # isort
    "N",      # pep8-naming
    "UP",     # pyupgrade
    "B",      # flake8-bugbear
    "C4",     # flake8-comprehensions
    "SIM",    # flake8-simplify
    "RUF",    # Ruff-specific rules
]
ignore = [
    "E501",   # line-too-long (gÃ©rÃ© par formatter)
]

[tool.ruff.lint.per-file-ignores]
"tests/**/*.py" = ["S101"]  # assert allowed in tests

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
```

**Commandes** :
```bash
ruff check .              # Lint
ruff check . --fix        # Auto-fix
ruff format .             # Format
ruff format . --check     # Check sans modifier
```

**RÃ¨gles projet** :
- âœ… ExÃ©cuter `ruff check . && ruff format .` avant chaque commit
- âœ… CI/CD doit bloquer si ruff Ã©choue
- âœ… Line length 88 (cohÃ©rence Black)
- âœ… Imports triÃ©s (isort intÃ©grÃ©)

---

### 3. Mypy - Type Checking Strict

**Configuration `pyproject.toml`** :

```toml
[tool.mypy]
python_version = "3.13"
strict = true
warn_return_any = true
warn_unused_configs = true
warn_redundant_casts = true
warn_unused_ignores = true
no_implicit_reexport = true
strict_equality = true

# Relax strict pour tests
[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false

# Ignorer libs sans stubs
[[tool.mypy.overrides]]
module = ["crawl4ai.*"]
ignore_missing_imports = true
```

**Flags activÃ©s par `strict = true`** :
- `--disallow-any-generics`
- `--disallow-untyped-defs`
- `--disallow-incomplete-defs`
- `--check-untyped-defs`
- `--disallow-untyped-decorators`
- `--warn-redundant-casts`
- `--warn-unused-ignores`
- `--warn-return-any`
- `--no-implicit-reexport`
- `--strict-equality`

**Commande** :
```bash
mypy app/
```

**RÃ¨gles projet** :
- âœ… Strict mode OBLIGATOIRE sur `app/`
- âœ… Relax sur `tests/` (moins contraignant)
- âœ… CI/CD doit bloquer si mypy Ã©choue
- âœ… Aucun `# type: ignore` sans justification commentÃ©e

---

### 4. Patterns Async (crawl4ai, error handling)

**Context managers async** :
```python
from crawl4ai import AsyncWebCrawler, BrowserConfig

async def fetch_flights(url: str) -> str:
    browser_config = BrowserConfig(
        browser_type="undetected",
        headless=True
    )

    async with AsyncWebCrawler(config=browser_config) as crawler:
        result = await crawler.arun(url)
        return result.html
```

**Error handling async avec tenacity** :
```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_random_exponential,
    retry_if_exception_type
)
import httpx

@retry(
    stop=stop_after_attempt(5),
    wait=wait_random_exponential(multiplier=1, max=60),
    retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError))
)
async def fetch_with_retry(url: str) -> str:
    async with httpx.AsyncClient(timeout=10) as client:
        response = await client.get(url)
        response.raise_for_status()
        return response.text
```

**RÃ¨gles projet** :
- âœ… TOUJOURS utiliser `async with` pour AsyncWebCrawler
- âœ… Retry logic avec tenacity (exponential backoff + jitter)
- âœ… Timeouts explicites (ex: `httpx.AsyncClient(timeout=10)`)
- âœ… Capturer exceptions spÃ©cifiques (pas `except Exception:`)
- âœ… Logger avant retry (`before_sleep` callback tenacity)

**Anti-patterns** :
- âŒ Bloquer event loop avec code sync dans routes async
- âŒ Retry sur 404 (erreur client, pas serveur)
- âŒ Pas de timeout â†’ risque hang

---

### 5. Structured Logging (JSON, contexte)

**Configuration logger** :
```python
import logging
import sys
from pythonjsonlogger import jsonlogger

def setup_logger(name: str) -> logging.Logger:
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)

    handler = logging.StreamHandler(sys.stdout)
    formatter = jsonlogger.JsonFormatter(
        "%(asctime)s %(name)s %(levelname)s %(message)s",
        timestamp=True
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    return logger

logger = setup_logger("flight-search-api")
```

**Usage avec contexte** :
```python
logger.info(
    "Flight search started",
    extra={
        "search_id": search_id,
        "destinations": destinations,
        "date_range": date_range,
        "proxy_used": proxy_host
    }
)

logger.warning(
    "Captcha detected",
    extra={
        "url": url,
        "retry_count": retry_count,
        "captcha_type": "recaptcha"
    }
)
```

**RÃ¨gles projet** :
- âœ… Format JSON structurÃ© (machine-readable)
- âœ… TOUJOURS ajouter `extra={}` avec contexte mÃ©tier
- âœ… Niveaux : DEBUG (dev), INFO (prod), WARNING (retry), ERROR (fail)
- âœ… Logger captcha detection, proxy rotation, parsing errors
- âœ… Pas de secrets dans logs (masquer API keys, passwords)

**MÃ©triques Ã  logger** :
- Search ID, destinations, dates
- Proxy utilisÃ©, bandwidth consommÃ©
- Captcha dÃ©tectÃ©s (type, URL, retry count)
- Parsing success/failure
- Top 10 rÃ©sultats

---

### 6. Docstrings Pragmatiques (PEP 257)

**RÃ¨gle : 1 ligne par dÃ©faut** (90% des cas) :

```python
def parse_price(html: str) -> float:
    """Extrait le prix depuis le HTML Google Flights."""
    ...

async def search_flights(request: SearchRequest) -> SearchResponse:
    """Orchestre la recherche de vols multi-destinations."""
    ...
```

**Format complet uniquement si nÃ©cessaire** :

```python
@retry(stop=stop_after_attempt(5))
async def crawl_with_proxy(url: str, proxy_config: ProxyConfig) -> str:
    """
    Crawl URL avec proxy et retry logic.

    Args:
        url: URL Google Flights Ã  crawler
        proxy_config: Configuration proxy Decodo

    Returns:
        HTML brut de la page

    Raises:
        CaptchaDetectedError: Si captcha dÃ©tectÃ© aprÃ¨s 5 tentatives
        ProxyRotationError: Si tous les proxies Ã©chouent
    """
    ...
```

**Quand utiliser format complet** :
- âœ… Comportement non-Ã©vident (side-effects, mutations)
- âœ… Exceptions importantes levÃ©es
- âœ… Algorithmes complexes (ex: combinaison generator)
- âœ… API publiques (routes FastAPI)

**RÃ¨gles projet** :
- âœ… 1 ligne suffit si signature explicite
- âœ… Pas de verbositÃ© (ne pas rÃ©pÃ©ter ce que le type dit dÃ©jÃ )
- âœ… Focus sur **POURQUOI**, pas **QUOI** (code montre le quoi)

**Anti-patterns** :
```python
# âŒ Redondant
def add(a: int, b: int) -> int:
    """Adds two integers and returns the result."""
    return a + b

# âœ… Inutile si Ã©vident
def add(a: int, b: int) -> int:
    return a + b
```

---

## ğŸš« Anti-Patterns

### Commentaires Inline Interdits

**RÃ¨gle stricte** : âŒ **AUCUN commentaire inline** sauf demande explicite user

**Pourquoi** :
- Code doit Ãªtre self-explanatory (noms explicites, types, docstrings)
- Commentaires deviennent obsolÃ¨tes rapidement
- Augmente bruit visuel

**Alternatives** :
```python
# âŒ Commentaire inline
price = float(html.select_one(".price").text.strip())  # Extract price from HTML

# âœ… Nom de fonction explicite
def extract_price(html: str) -> float:
    """Extrait le prix depuis le HTML."""
    return float(html.select_one(".price").text.strip())
```

**Exceptions autorisÃ©es** :
- âœ… User demande explicitement commentaires
- âœ… TODO/FIXME temporaires (Ã  rÃ©soudre avant merge)
- âœ… Type hints complexes nÃ©cessitant clarification

**ConsÃ©quence** : PR rejetÃ©e si commentaires inline non justifiÃ©s

---

## ğŸ“ Organisation Fichiers

_Ã€ complÃ©ter en Phase 2.3_

---

## ğŸ”„ Workflow DÃ©veloppement

_Ã€ complÃ©ter en Phase 2.3_

---

## ğŸ§ª Tests

_Ã€ complÃ©ter en Phase 2.3_

---

## ğŸ³ Docker

_Ã€ complÃ©ter en Phase 2.3_

---

## ğŸ“¦ Git

_Ã€ complÃ©ter en Phase 0.2 et Phase 1.5_

# Plan d'action complet - flight-search-api

## Phase 0 : Setup Documentation & Git

**Objectif** : Initialiser la structure documentation (Git dÃ©jÃ  connectÃ©)

**PrÃ©requis (DÃ‰JÃ€ FAIT)** :
- âœ… Repo GitHub crÃ©Ã© et clonÃ©
- âœ… Remote configurÃ©
- âœ… CrÃ©er dossier .claude (oÃ¹ figure le plan)

### 0.1 Structure documentation vide
- [ ] CrÃ©er `docs/`
- [ ] CrÃ©er `.claude/CLAUDE.md`
- [ ] CrÃ©er `docs/architecture.md`
- [ ] CrÃ©er `docs/PLANNING.md`
- [ ] CrÃ©er `docs/REFERENCES.md`
- [ ] CrÃ©er `docs/VERSIONS.md`
- [ ] CrÃ©er `docs/CHANGELOG.md`
- [ ] Commit : `docs: create documentation structure`
- [ ] Push main et crÃ©er branche develop

ðŸ“ **Output** : Structure docs prÃªte Ã  remplir

---

## Phase 1 : Recherche & Documentation

**Objectif** : Construire la base de connaissance avant tout dev

**Branche** : `feature/research-stack`

### 1.1 Recherche versions & compatibilitÃ©
- [ ] Python 3.13 stabilitÃ© et compatibilitÃ© Ã©cosystÃ¨me
- [ ] FastAPI 0.121.2 (breaking changes, Pydantic v2)
- [ ] Pydantic v2.10+ (migration depuis v1)
- [ ] tenacity 9.0+ (retry strategies)
- [ ] crawl4ai 0.7+ (async crawler, stealth mode, Playwright intÃ©grÃ©)
- [ ] VÃ©rification matrice compatibilitÃ© croisÃ©e
- [ ] CrÃ©er `docs/VERSIONS.md` avec tableau + notes
- [ ] Commit : `docs: add versions compatibility matrix`

ðŸ“ **Output** : `docs/VERSIONS.md`

**Note** : Playwright est installÃ© automatiquement par `crawl4ai-setup`, pas besoin de l'installer sÃ©parÃ©ment.

### 1.2 Documentation technique ciblÃ©e
- [ ] FastAPI : Dependency Injection, async routes, TestClient
      â†’ https://fastapi.tiangolo.com/
- [ ] Pydantic v2 : Settings, validation, field_validator
      â†’ https://docs.pydantic.dev/latest/
- [ ] Crawl4AI : AsyncWebCrawler, BrowserConfig, JsonCssExtractionStrategy (extraction CSS)
      â†’ https://docs.crawl4ai.com/
- [ ] Decodo Proxies : Residential rotation, France targeting, authentication, bandwidth optimization
      â†’ https://help.decodo.com/docs/introduction
        **Note** : Format auth = username: customer-{api_key}-country-FR, password: your_password
- [ ] Google Flights URL structure : Multi-city params, date formats, currency/locale (France)
      â†’ (reverse engineering via browser DevTools)
- [ ] Anti-dÃ©tection : Stealth mode Crawl4AI, user-agent rotation, proxy rotation
      â†’ https://docs.crawl4ai.com/core/browser-config/
- [ ] Captcha detection : Patterns HTML (reCAPTCHA, hCaptcha), retry strategy avec rotation IP
      â†’ (patterns de dÃ©tection, pas de rÃ©solution dans MVP)
- [ ] Tenacity : @retry decorator, wait strategies, async
      â†’ https://tenacity.readthedocs.io/
- [ ] Dokploy : Dockerfile best practices, env vars
      â†’ https://docs.dokploy.com/
- [ ] CrÃ©er `docs/REFERENCES.md` avec extraits + liens
- [ ] Commit : `docs: add technical references`

ðŸ“ **Output** : `docs/REFERENCES.md`

**Note** : Si features additionnelles nÃ©cessaires pendant l'implÃ©mentation, les documenter dans un ADR et mettre Ã  jour REFERENCES.md.

### 1.3 Standards Python modernes
- [ ] Python 3.13 type hints (PEP 695)
- [ ] Ruff configuration (rules, pyproject.toml)
- [ ] Mypy strict mode
- [ ] Async patterns (crawl4ai, error handling)
- [ ] Structured logging (JSON, contexte)
- [ ] Docstrings pragmatiques (PEP 257 : 1 ligne par dÃ©faut)
- [ ] ComplÃ©ter `.claude/CLAUDE.md` - Section Standards
- [ ] Ajouter rÃ¨gle anti-pattern : commentaires inline interdits
- [ ] Commit : `docs: add Python standards to CLAUDE.md`

ðŸ“ **Output** : `.claude/CLAUDE.md` - Section Standards

### 1.4 Architecture & DÃ©cisions (ADR)
- [ ] CrÃ©er diagrammes (composants, sÃ©quence)
- [ ] Documenter flow de donnÃ©es (RequÃªte HTTP â†’ Services internes â†’ Response JSON)
- [ ] RÃ©diger ADR #001 : Crawl4AI+Proxies vs SerpAPI (coÃ»t, flexibilitÃ©, maintenance)
- [ ] RÃ©diger ADR #002 : Decodo vs Oxylabs (prix, pool IP, France targeting)
- [ ] RÃ©diger ADR #003 : Top 10 en mÃ©moire (pas de DB)
- [ ] RÃ©diger ADR #004 : Tenacity pour retry
- [ ] RÃ©diger ADR #005 : Captcha handling strategy (proxies rotation + detection, pas de rÃ©solution dans MVP)
- [ ] RÃ©diger ADR #006 : JsonCssExtractionStrategy vs LLMExtractionStrategy (coÃ»t, performance)
- [ ] CrÃ©er `docs/architecture.md` avec ADR intÃ©grÃ©s
- [ ] Commit : `docs: add architecture and ADR`

ðŸ“ **Output** : `docs/architecture.md`

### 1.5 Conventions Git
- [ ] Documenter stratÃ©gie branches (main/develop/feature)
- [ ] Documenter Conventional Commits (feat, fix, docs, etc.)
- [ ] Documenter pre-commit checks (ruff, mypy, pytest)
- [ ] Documenter workflow dÃ©veloppement
- [ ] ComplÃ©ter `.claude/CLAUDE.md` - Section Git
- [ ] Commit : `docs: add git conventions to CLAUDE.md`

ðŸ“ **Output** : `.claude/CLAUDE.md` - Section Git

### 1.6 Mise Ã  jour CHANGELOG
- [ ] Ajouter entrÃ©e v0.1.0-research dans `docs/CHANGELOG.md`
- [ ] Commit : `docs: update changelog for research phase`

ðŸ“ **Output** : `docs/CHANGELOG.md` mis Ã  jour

### 1.7 Merge recherche
- [ ] Merger `feature/research-stack` dans `develop`
- [ ] Tag `v0.1.0-research`
- [ ] Push develop + tags

---

## Phase 2 : Architecture & Squelette

**Objectif** : CrÃ©er la structure complÃ¨te du projet

**Branche** : `feature/project-structure`

### 2.1 CrÃ©ation structure complÃ¨te
- [ ] CrÃ©er fichiers racine : `README.md`, `.gitignore`, `.dockerignore`, `Dockerfile`, `pyproject.toml`, `.env.example`
- [ ] CrÃ©er structure `app/` avec tous dossiers et fichiers
- [ ] CrÃ©er structure `tests/` avec unit/ et integration/
- [ ] Ajouter docstrings TODO dans tous fichiers Python
- [ ] Commit : `chore: create project structure skeleton`

ðŸ“ **Output** : Arborescence complÃ¨te avec fichiers vides + TODO

### 2.2 Configuration fichiers systÃ¨me
- [ ] Remplir `.gitignore` (Python, tests, IDEs, env, Docker, OS)
- [ ] Remplir `.dockerignore`
- [ ] CrÃ©er `.env.example` avec variables :
      - LOG_LEVEL=INFO
      - DECODO_USERNAME=customer-XXXX-country-FR
      - DECODO_PASSWORD=your_password
      - DECODO_PROXY_HOST=pr.decodo.com:8080
      - PROXY_ROTATION_ENABLED=true
      - CAPTCHA_DETECTION_ENABLED=true
- [ ] Commit : `chore: add system configuration files`

ðŸ“ **Output** : Fichiers config systÃ¨me prÃªts

### 2.3 ComplÃ©ter CLAUDE.md
- [ ] VÃ©rifier section Contexte projet
- [ ] VÃ©rifier section Standards (dÃ©jÃ  fait Phase 1.3)
- [ ] Ajouter section Organisation fichiers (arborescence)
- [ ] VÃ©rifier section Anti-patterns
- [ ] VÃ©rifier section Git (dÃ©jÃ  fait Phase 1.5)
- [ ] Ajouter section Workflow dÃ©veloppement
- [ ] Ajouter section Tests (pytest commands)
- [ ] Ajouter section Docker (build/run)
- [ ] Commit si modifs : `docs: finalize CLAUDE.md`

ðŸ“ **Output** : `.claude/CLAUDE.md` complet

### 2.4 Mise Ã  jour CHANGELOG
- [ ] Ajouter entrÃ©e v0.2.0-structure dans `docs/CHANGELOG.md`
- [ ] Commit : `docs: update changelog for structure phase`

ðŸ“ **Output** : `docs/CHANGELOG.md` mis Ã  jour

### 2.5 Merge structure
- [ ] Merger `feature/project-structure` dans `develop`
- [ ] Tag `v0.2.0-structure`
- [ ] Push develop + tags

---

## Phase 3 : Configuration & Build

**Objectif** : Projet runnable avec config minimale

**Branche** : `feature/config-build`

### 3.1 pyproject.toml complet
- [ ] Section [project] : metadata + dependencies (fastapi, pydantic, crawl4ai, tenacity)
- [ ] Section [project.optional-dependencies] : dev tools
- [ ] Section [tool.ruff] : linting rules + formatting
- [ ] Section [tool.mypy] : strict mode + overrides
- [ ] Section [tool.pytest.ini_options] : test config + coverage
- [ ] Commit : `chore(config): add complete pyproject.toml`

ðŸ“ **Output** : `pyproject.toml` complet

### 3.2 Dockerfile multi-stage optimisÃ©
- [ ] Stage 1 Builder : install uv + dependencies + crawl4ai-setup
      **Note** : crawl4ai-setup installe automatiquement Playwright + dÃ©pendances systÃ¨me
- [ ] Stage 2 Runtime : copy deps + code, non-root user, healthcheck
- [ ] OptimisÃ© pour Dokploy
- [ ] Commit : `chore(docker): add optimized Dockerfile`

ðŸ“ **Output** : `Dockerfile` production-ready

### 3.3 App minimale + health endpoint
- [ ] ImplÃ©menter `app/main.py` : FastAPI app basique
- [ ] ImplÃ©menter endpoint GET `/health` â†’ `{"status": "ok"}`
- [ ] ImplÃ©menter `tests/integration/test_health.py`
- [ ] Commit : `feat(api): add minimal app with health endpoint`

ðŸ“ **Output** : App minimale testable

### 3.4 VÃ©rifications locales
- [ ] Install deps : `uv sync --all-extras`
- [ ] Run post-install : `crawl4ai-setup` (installe Playwright)
- [ ] Run app : `fastapi dev app/main.py`
- [ ] Test health : `curl http://localhost:8000/health`
- [ ] Run tests : `pytest -v`
- [ ] Lint : `ruff check . && ruff format . --check`
- [ ] Type check : `mypy app/`
- [ ] Build Docker : `docker build -t flight-search-api .`
- [ ] Run Docker : `docker run -p 8000:8000 flight-search-api`
- [ ] Test Docker health : `curl http://localhost:8000/health`
- [ ] Commit : `chore: verify local and docker builds`

ðŸ“ **Output** : VÃ©rification que tout fonctionne

### 3.5 Mise Ã  jour CHANGELOG
- [ ] Ajouter entrÃ©e v0.3.0-build dans `docs/CHANGELOG.md`
- [ ] Commit : `docs: update changelog for build phase`

ðŸ“ **Output** : `docs/CHANGELOG.md` mis Ã  jour

### 3.6 Merge config
- [ ] Merger `feature/config-build` dans `develop`
- [ ] Tag `v0.3.0-build`
- [ ] Push develop + tags

---

## Phase 4 : Planning dÃ©taillÃ© dÃ©veloppement

**Objectif** : Ã‰crire les specs prÃ©cises avant de coder

**Branche** : `feature/planning-specs`

### 4.1 SpÃ©cifications Models
- [ ] Specs SearchRequest (Flight, DateRange, validation)
- [ ] Specs SearchResponse (FlightResult, SearchStats)
- [ ] Liste tests unitaires
- [ ] Ajouter Ã  `docs/PLANNING.md`

### 4.2 SpÃ©cifications Configuration & Logging
- [ ] Specs Settings class (Pydantic Settings)
- [ ] Specs logger setup (JSON structurÃ©)
- [ ] Liste tests
- [ ] Ajouter Ã  `docs/PLANNING.md`

### 4.3 SpÃ©cifications Services
- [ ] Specs CombinationGenerator (algorithme itertools.product)
- [ ] Specs ProxyService (Decodo config, rotation strategy, bandwidth monitoring)
- [ ] Specs CrawlerService (Crawl4AI setup, stealth mode, captcha detection, retry logic)
- [ ] Specs FlightParserService (JsonCssExtractionStrategy, parsing vols/prix/horaires)
- [ ] Specs SearchService (orchestration : CombinationGenerator â†’ CrawlerService â†’ FlightParser â†’ Top 10 ranking)
- [ ] Liste tests pour chaque service
- [ ] Ajouter Ã  `docs/PLANNING.md`

### 4.4 SpÃ©cifications API Routes
- [ ] Specs endpoint POST /api/v1/search-flights
- [ ] Validation request (Pydantic)
- [ ] Error handling (400, 500, 207)
- [ ] Tests intÃ©gration (happy path + errors)
- [ ] Ajouter Ã  `docs/PLANNING.md`

### 4.5 StratÃ©gie tests
- [ ] Liste complÃ¨te tests unitaires par composant
- [ ] ScÃ©narios tests intÃ©gration
- [ ] Mocks strategy (Crawl4AI, Decodo proxies, HTML responses Google Flights)
- [ ] Tests captcha detection et retry logic
- [ ] Tests proxy rotation et fallback
- [ ] Coverage target : 80%
- [ ] Ajouter Ã  `docs/PLANNING.md`

### 4.6 Finalisation PLANNING.md
- [ ] VÃ©rifier cohÃ©rence globale
- [ ] Commit : `docs: add detailed development planning`

ðŸ“ **Output** : `docs/PLANNING.md` ultra-dÃ©taillÃ©

### 4.7 Mise Ã  jour CHANGELOG
- [ ] Ajouter entrÃ©e v0.4.0-planning dans `docs/CHANGELOG.md`
- [ ] Commit : `docs: update changelog for planning phase`

ðŸ“ **Output** : `docs/CHANGELOG.md` mis Ã  jour

### 4.8 Merge planning
- [ ] Merger `feature/planning-specs` dans `develop`
- [ ] Tag `v0.4.0-planning`
- [ ] Push develop + tags

---

## Phase 5 : ImplÃ©mentation MVP (TDD)

**Objectif** : DÃ©velopper tous les composants avec approche TDD (sans rÃ©solution captcha)

**Branche** : `feature/implementation`

### 5.1 Models (Pydantic)
- [ ] Ã‰crire tests `tests/unit/test_models.py`
- [ ] ImplÃ©menter `app/models/request.py`
- [ ] ImplÃ©menter `app/models/response.py`
- [ ] VÃ©rifier tests passent
- [ ] Commit : `feat(models): add pydantic models with validation`

### 5.2 Configuration & Logging
- [ ] Ã‰crire tests `tests/unit/test_config.py`
- [ ] ImplÃ©menter `app/core/config.py`
- [ ] ImplÃ©menter `app/core/logger.py`
- [ ] VÃ©rifier tests passent
- [ ] Commit : `feat(core): add config and structured logging`

### 5.3 CombinationGenerator
- [ ] Ã‰crire tests `tests/unit/test_combination_generator.py`
- [ ] ImplÃ©menter `app/services/combination_generator.py`
- [ ] VÃ©rifier tests passent
- [ ] Commit : `feat(services): add combination generator`

### 5.4 ProxyService
- [ ] Ã‰crire tests `tests/unit/test_proxy_service.py`
- [ ] ImplÃ©menter `app/services/proxy_service.py` (Decodo config, rotation)
- [ ] VÃ©rifier tests passent
- [ ] Commit : `feat(services): add proxy service with Decodo integration`

### 5.5 CrawlerService + Captcha Detection
- [ ] Ã‰crire tests `tests/unit/test_crawler_service.py` (avec mocks Crawl4AI)
- [ ] ImplÃ©menter `app/services/crawler_service.py` (retry avec tenacity)
- [ ] ImplÃ©menter dÃ©tection captcha (logger uniquement, pas de rÃ©solution)
- [ ] VÃ©rifier tests passent
- [ ] Commit : `feat(services): add crawler service with captcha detection`

### 5.6 FlightParserService
- [ ] Ã‰crire tests `tests/unit/test_flight_parser.py` (avec HTML fixtures)
- [ ] ImplÃ©menter `app/services/flight_parser.py` (JsonCssExtractionStrategy)
- [ ] VÃ©rifier tests passent
- [ ] Commit : `feat(services): add flight parser service`

### 5.7 SearchService
- [ ] Ã‰crire tests `tests/unit/test_search_service.py`
- [ ] ImplÃ©menter `app/services/search_service.py`
- [ ] VÃ©rifier tests passent
- [ ] Commit : `feat(services): add search orchestration service`

### 5.8 API Routes
- [ ] Ã‰crire tests `tests/integration/test_api_routes.py`
- [ ] ImplÃ©menter `app/api/routes.py`
- [ ] IntÃ©grer dans `app/main.py`
- [ ] VÃ©rifier tests passent
- [ ] Commit : `feat(api): add search endpoint`

### 5.9 Tests coverage
- [ ] Lancer `pytest --cov=app --cov-report=html`
- [ ] VÃ©rifier >80% coverage
- [ ] Ajouter tests si nÃ©cessaire
- [ ] Commit : `test: ensure 80% coverage`

### 5.10 VÃ©rifications finales
- [ ] Lint : `ruff check . && ruff format .`
- [ ] Type check : `mypy app/`
- [ ] Tests : `pytest -v`
- [ ] Build Docker : `docker build -t flight-search-api .`
- [ ] Test complet local avec vraie clÃ© Decodo (1-2 recherches test)
- [ ] VÃ©rifier logs : captcha detection, proxy rotation, parsing success
- [ ] Commit : `chore: final verifications before release`

### 5.11 Mise Ã  jour CHANGELOG
- [ ] Ajouter entrÃ©e v0.5.0-mvp dans `docs/CHANGELOG.md`
- [ ] Commit : `docs: update changelog for MVP implementation`

ðŸ“ **Output** : API MVP complÃ¨te et testÃ©e (sans rÃ©solution captcha)

### 5.12 Merge implementation
- [ ] Merger `feature/implementation` dans `develop`
- [ ] Tag `v0.5.0-mvp`
- [ ] Push develop + tags

---

## Phase 6 : Documentation finale & Release MVP

**Objectif** : README professionnel et release v1.0.0

**Branche** : `feature/documentation`

### 6.1 README.md complet
- [ ] Section Description projet
- [ ] Section PrÃ©requis (Python 3.13, Docker, uv)
- [ ] Section Installation locale
- [ ] Section Configuration (env vars)
- [ ] Section Usage (exemples curl)
- [ ] Section Tests (commandes pytest)
- [ ] Section DÃ©ploiement Dokploy
- [ ] Section Limites connues (Decodo bandwidth costs, Google rate limits, captcha detection only)
- [ ] Section Monitoring (coÃ»ts proxies, taux de succÃ¨s, captcha rate)
- [ ] Commit : `docs: add complete README`

ðŸ“ **Output** : README.md professionnel

### 6.2 CHANGELOG v1.0.0
- [ ] Consolider toutes les entrÃ©es prÃ©cÃ©dentes
- [ ] CrÃ©er section v1.0.0 avec features complÃ¨tes
- [ ] Commit : `docs: release v1.0.0 changelog`

ðŸ“ **Output** : CHANGELOG.md complet

### 6.3 Merge documentation
- [ ] Merger `feature/documentation` dans `develop`
- [ ] Merger `develop` dans `main`
- [ ] Tag `v1.0.0`
- [ ] Push main + develop + tags

### 6.4 Release GitHub
- [ ] CrÃ©er release sur GitHub avec tag v1.0.0
- [ ] Copier CHANGELOG v1.0.0 dans release notes

ðŸ“ **Output** : Release v1.0.0 publique (MVP sans rÃ©solution captcha)

---

## DÃ©ploiement Dokploy

**Objectif** : DÃ©ployer MVP en production

### DÃ©ploiement
- [ ] Configurer Dokploy : connecter repo GitHub
- [ ] Ajouter env vars dans UI Dokploy :
      - LOG_LEVEL
      - DECODO_USERNAME
      - DECODO_PASSWORD
      - DECODO_PROXY_HOST
      - PROXY_ROTATION_ENABLED
      - CAPTCHA_DETECTION_ENABLED
- [ ] DÃ©clencher build automatique (push sur main)
- [ ] VÃ©rifier deployment : `curl https://ton-domaine.com/health`
- [ ] Tester endpoint complet avec n8n
- [ ] Monitorer logs : captcha rate, proxy costs, success rate

ðŸ“ **Output** : API MVP en production avec monitoring actif

---

## Phase 7 : Captcha Solving (Post-MVP - Optionnelle)

**Objectif** : Ajouter rÃ©solution automatique captchas **uniquement si monitoring Phase 6 montre trop de blocages**

**PrÃ©-requis** : 
- âœ… MVP dÃ©ployÃ© et monitoring actif
- âœ… Logs captcha rate analysÃ©s sur 1-2 semaines minimum
- âœ… DÃ©cision data-driven basÃ©e sur mÃ©triques rÃ©elles

**Branche** : `feature/captcha-solving`

### 7.1 Analyse & dÃ©cision
- [ ] Analyser logs monitoring : calculer taux de captcha (nombre captchas / nombre total requÃªtes) sur 1-2 semaines minimum
- [ ] Calculer impact business : % de recherches Ã©chouÃ©es Ã  cause captchas
- [ ] DÃ©cider si 2Captcha nÃ©cessaire (seuil recommandÃ© : >5% blocages)
- [ ] Si taux < 5%, STOP ici (pas besoin de Phase 7)
- [ ] Si taux â‰¥ 5%, continuer Phase 7
- [ ] Documenter dÃ©cision dans ADR #007 : "2Captcha Integration Decision"

ðŸ“ **Output** : DÃ©cision documentÃ©e (GO ou NO-GO Phase 7)

### 7.2 Recherche 2Captcha
- [ ] Documentation 2Captcha : API, pricing, types captchas supportÃ©s
      â†’ https://2captcha.com/2captcha-api
- [ ] Estimation coÃ»ts : nombre captchas/mois Ã— $0.001-0.003
- [ ] Comparer avec coÃ»t des recherches perdues
- [ ] Valider ROI positif
- [ ] Ajouter Ã  `docs/REFERENCES.md`

### 7.3 IntÃ©gration 2Captcha
- [ ] Ajouter `2captcha-python` Ã  pyproject.toml
- [ ] CrÃ©er `app/services/captcha_solver.py`
- [ ] Ã‰crire tests `tests/unit/test_captcha_solver.py` (avec mocks)
- [ ] Modifier `CrawlerService` pour fallback 2Captcha si dÃ©tection captcha
- [ ] Ajouter env vars :
      - TWOCAPTCHA_API_KEY
      - CAPTCHA_SOLVING_ENABLED (default: false)
- [ ] Mettre Ã  jour `.env.example`
- [ ] VÃ©rifier tests passent
- [ ] Commit : `feat(services): add 2captcha fallback for captcha solving`

### 7.4 Tests & validation
- [ ] Tests intÃ©gration avec mock 2Captcha
- [ ] Test complet local avec vraie clÃ© 2Captcha
- [ ] VÃ©rifier coÃ»ts rÃ©els par captcha rÃ©solu
- [ ] VÃ©rifier temps rÃ©solution acceptable (<30s)
- [ ] Coverage >80%
- [ ] Commit : `test: add captcha solver integration tests`

### 7.5 Monitoring coÃ»ts
- [ ] Logger coÃ»ts 2Captcha par recherche
- [ ] Ajouter mÃ©triques Prometheus/Grafana :
      - Nombre captchas rÃ©solus/jour
      - CoÃ»t 2Captcha/jour
      - Taux de succÃ¨s rÃ©solution
      - Temps moyen rÃ©solution
- [ ] Dashboard monitoring dÃ©diÃ©
- [ ] Documentation ROI : coÃ»t captcha vs perte de donnÃ©es
- [ ] Commit : `feat(monitoring): add 2captcha cost tracking`

### 7.6 Documentation
- [ ] Mettre Ã  jour README : section Captcha Solving
- [ ] Mettre Ã  jour PLANNING.md : stratÃ©gie captcha complÃ¨te
- [ ] Ajouter ADR #007 dans architecture.md
- [ ] Commit : `docs: add captcha solving documentation`

### 7.7 Mise Ã  jour CHANGELOG
- [ ] Ajouter entrÃ©e v1.1.0-captcha dans `docs/CHANGELOG.md`
- [ ] Commit : `docs: update changelog for captcha solving phase`

### 7.8 Merge & release
- [ ] Merger `feature/captcha-solving` dans `develop`
- [ ] Tests complets sur develop
- [ ] Merger `develop` dans `main`
- [ ] Tag `v1.1.0`
- [ ] Push main + develop + tags
- [ ] Release GitHub v1.1.0

### 7.9 DÃ©ploiement
- [ ] Ajouter TWOCAPTCHA_API_KEY dans Dokploy
- [ ] Activer CAPTCHA_SOLVING_ENABLED=true
- [ ] DÃ©ployer v1.1.0
- [ ] Monitorer coÃ»ts et efficacitÃ© pendant 1 semaine
- [ ] Ajuster seuils si nÃ©cessaire

ðŸ“ **Output** : Captcha solving en production avec ROI positif

---

## Notes importantes

### Docstrings (rÃ¨gle pragmatique)
- **1 ligne par dÃ©faut** : Suffit pour 90% des cas
- **Format complet** : Uniquement si comportement non-Ã©vident, side-effects, ou exceptions importantes
- **Pas de verbositÃ©** : Ne pas rÃ©pÃ©ter ce que la signature dit dÃ©jÃ 

### Commentaires inline
- **âŒ Interdits** sauf demande explicite user
- Code doit Ãªtre self-explanatory

### Tests
- **Unitaires** : Avec mocks (Crawl4AI, Decodo proxies, HTML Google Flights)
- **Tests captcha** : Mock dÃ©tection + retry scenarios
- **IntÃ©gration** : TestClient FastAPI
- **Coverage** : Minimum 80%

### Git workflow
- Toujours travailler sur feature branches
- Merger dans develop
- Release : develop â†’ main avec tag

### Stack Crawl4AI + Proxies

**Architecture scraping** :
- **Crawl4AI** : AsyncWebCrawler avec stealth mode (Playwright intÃ©grÃ© automatiquement)
- **Extraction** : JsonCssExtractionStrategy (pas de coÃ»ts API LLM)
- **Decodo Proxies** : Residential rotation automatique (France), ~$4/GB
- **Anti-dÃ©tection** : Stealth mode natif Crawl4AI, user-agent rotation

**Captcha handling (approche progressive)** :

**Phase MVP (Phase 5-6)** :
- Proxies rÃ©sidentiels Decodo (Ã©vite 95%+ des captchas)
- Stealth mode Crawl4AI (anti-dÃ©tection native)
- Retry avec rotation IP (contourne captchas temporaires)
- **DÃ©tection captcha** : Log uniquement, pas de rÃ©solution
- **Monitoring** : Taux de captcha, impact business

**Phase Post-MVP (Phase 7 - Optionnelle si monitoring montre >5% blocages)** :
- IntÃ©gration 2Captcha en fallback
- CoÃ»t additionnel : ~$0.001-0.003 par captcha rÃ©solu
- DÃ©cision data-driven aprÃ¨s analyse logs production
- ROI validÃ© avant implÃ©mentation

**Optimisations bandwidth** :
- DÃ©sactiver images, CSS, ads, scripts inutiles dans Crawl4AI
- Ã‰conomie attendue : ~90% vs scraping full page
- CoÃ»t estimÃ© : 0.0008â‚¬ par recherche (~200KB/recherche)

**Pas de coÃ»ts LLM** :
- Pas d'API key OpenAI/Anthropic/Claude nÃ©cessaire
- Extraction pure CSS selectors (gratuit)
- LLM optionnel uniquement si structure HTML imprÃ©visible (hors scope MVP)

**Monitoring requis** :
- Taux de captcha par recherche (dÃ©cision Phase 7)
- Bandwidth consommÃ© (GB/jour)
- CoÃ»t proxies mensuel
- Taux de succÃ¨s parsing
- (Si Phase 7) CoÃ»t 2Captcha mensuel

### Structure finale
```
flight-search-api/
â”œâ”€â”€ .claude/
â”‚   â”œâ”€â”€ CLAUDE.md      # Standards, conventions
â”‚   â””â”€â”€ PLAN.md        # Ce plan
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ PLANNING.md
â”‚   â”œâ”€â”€ REFERENCES.md
â”‚   â”œâ”€â”€ VERSIONS.md
â”‚   â””â”€â”€ CHANGELOG.md
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ request.py
â”‚   â”‚   â””â”€â”€ response.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ combination_generator.py
â”‚   â”‚   â”œâ”€â”€ proxy_service.py
â”‚   â”‚   â”œâ”€â”€ crawler_service.py
â”‚   â”‚   â”œâ”€â”€ flight_parser.py
â”‚   â”‚   â”œâ”€â”€ search_service.py
â”‚   â”‚   â””â”€â”€ (captcha_solver.py - Phase 7 optionnelle)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_models.py
â”‚   â”‚   â”œâ”€â”€ test_config.py
â”‚   â”‚   â”œâ”€â”€ test_combination_generator.py
â”‚   â”‚   â”œâ”€â”€ test_proxy_service.py
â”‚   â”‚   â”œâ”€â”€ test_crawler_service.py
â”‚   â”‚   â”œâ”€â”€ test_flight_parser.py
â”‚   â”‚   â”œâ”€â”€ test_search_service.py
â”‚   â”‚   â””â”€â”€ (test_captcha_solver.py - Phase 7)
â”‚   â””â”€â”€ integration/
â”‚       â”œâ”€â”€ test_health.py
â”‚       â””â”€â”€ test_api_routes.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

### DÃ©pendances principales
```toml
[project]
dependencies = [
    "fastapi>=0.121.2",
    "pydantic>=2.10",
    "pydantic-settings>=2.0",
    "crawl4ai>=0.7",  # Inclut Playwright automatiquement
    "tenacity>=9.0",
    "uvicorn>=0.30",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0",
    "pytest-asyncio>=0.23",
    "pytest-cov>=4.1",
    "ruff>=0.6",
    "mypy>=1.11",
]

# Si Phase 7 activÃ©e :
# captcha = [
#     "2captcha-python>=1.4",
# ]
```
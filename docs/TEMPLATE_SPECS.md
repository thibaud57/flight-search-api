---
title: "Story X: [Nom story]"
epic: "Epic X: [Nom epic]"
story_points: 0
dependencies: []
date: "YYYY-DD-MM"
keywords: []
scope: ["specs"]
technologies: []
---

<!--
‚ö†Ô∏è R√àGLES IMPORTANTES - Sp√©cifications (√† titre informatif, ne pas inclure dans stories)

**Ce template doit contenir UNIQUEMENT** :
- ‚úÖ Interfaces/signatures (SANS impl√©mentation)
- ‚úÖ Descriptions comportements (texte structur√©)
- ‚úÖ Tableaux sc√©narios tests (descriptif, PAS code Python)
- ‚úÖ Exemples JSON (inputs/outputs)

**CODE PRODUCTION INTERDIT** :
- ‚ùå Impl√©mentation compl√®te fonctions/classes
- ‚ùå Logique m√©tier (algorithmes, boucles, conditions)
- ‚ùå Tests Python √©crits

**Principe fondamental** :
- (Specs) = QUOI faire ‚Üí D√©crire comportements attendus
- (TDD) = COMMENT faire ‚Üí Impl√©menter code production

Note: Agent DOCUMENT respecte automatiquement ces r√®gles selon type "specs"
-->

# üéØ Contexte Business

## Besoin utilisateur
- [D√©crire le besoin m√©tier concret]
- [Qui utilise cette feature ?]
- [Quel probl√®me r√©sout-elle ?]

## Contraintes m√©tier
- [Contrainte 1: limites techniques, budgets, SLA]
- [Contrainte 2]
- [Contrainte 3]
- ...

## Valeur business
- ‚úÖ [Valeur 1: qu'apporte cette story au client final ?]
- ‚úÖ [Valeur 2: feedback rapide, validation early, d√©risquage]
- ‚úÖ [Valeur 3: foundation pour stories futures]
- ‚úÖ [Valeur 4: m√©triques observables]
- ...

## M√©triques succ√®s
- [M√©trique 1: temps de r√©ponse, taux d'erreur, etc.]
- [M√©trique 2: adoption client, feedback qualitatif]
- [M√©trique 3: coverage tests, qualit√© code]
- ...

---

# üìã Sp√©cifications Techniques

## 1. [Composant 1]

**R√¥le**: [D√©crire responsabilit√© unique du composant]

**Interface**:
```python
class ComposantExemple:
    """Docstring 1 ligne."""

    def methode_principale(self, param: Type) -> ReturnType:
        """Docstring m√©thode."""
```

**Champs/Param√®tres**:

| Champ | Type | Description | Contraintes |
|-------|------|-------------|-------------|
| `field_name` | `str` | Description | min_length=2, max_length=100 |
| `field_number` | `int` | Description | ‚â• 0, ‚â§ 1000 |

**Comportement**:
- [Comportement normal]
- [Edge cases]
- [Erreurs lev√©es]

**Validations** (si Pydantic):
- `field_validator`: [Validation custom]
- `model_validator`: [Validation cross-field]

## 2. [Composant 2]

[R√©p√©ter structure similaire pour chaque composant de la story]

---

# üß™ Tests

## Tests unitaires (TDD)

**Format recommand√©: AAA (Arrange/Act/Assert)**

### [Composant 1] (X tests)

**Format tableau descriptif** (6 colonnes) :

| # | Nom test | Sc√©nario | Input | Output attendu | V√©rification |
|---|----------|----------|-------|----------------|--------------|
| 1 | `test_composant_valid_input` | Composant avec input valide | `{"key": "value"}` | `result.success == True` | V√©rifie comportement nominal |
| 2 | `test_composant_edge_case` | Input avec string vide | `{"key": ""}` | L√®ve `ValidationError` | V√©rifie validation edge case |
| 3 | `test_composant_async` | Appel fonction async | `await composant.call()` | `result` not None | V√©rifie fonction async retourne valeur |

**Colonnes** :
- **#** : Num√©ro test (ordre logique)
- **Nom test** : Nom fonction test √† √©crire en Phase 5 (format `test_[composant]_[scenario]`)
- **Sc√©nario** : Description comportement test√© (1 phrase courte)
- **Input** : Donn√©es entr√©e (format compact, ex: `{"key": "value"}`)
- **Output attendu** : R√©sultat attendu (assertion principale)
- **V√©rification** : Explication v√©rification (POURQUOI ce test est important)

### [Composant 2] (Y tests)

[R√©p√©ter tableau tests + exemple pour chaque composant]

**Total tests unitaires**: X + Y = Z tests

---

## Tests int√©gration

**Format recommand√©: Given/When/Then (BDD)**

**Format tableau descriptif** (5 colonnes pour tests int√©gration) :

| # | Nom test | Pr√©requis (Given) | Action (When) | R√©sultat attendu (Then) |
|---|----------|-------------------|---------------|-------------------------|
| 1 | `test_integration_happy_path` | App running, client TestClient | POST /endpoint avec data valide | Status 200 + JSON conforme sch√©ma |
| 2 | `test_integration_validation_error` | App running | POST /endpoint avec data invalide | Status 400 + error message clair |
| 3 | `test_integration_edge_case` | State X configur√© | Action Y ex√©cut√©e | Result Z v√©rifi√© |

**Colonnes** :
- **#** : Num√©ro test
- **Nom test** : Nom fonction test √† √©crire en Phase 5
- **Pr√©requis (Given)** : √âtat initial et pr√©conditions
- **Action (When)** : Action ex√©cut√©e (ex: requ√™te HTTP, appel fonction)
- **R√©sultat attendu (Then)** : R√©sultat v√©rifi√© (status code, donn√©es retourn√©es, side-effects)

**Total tests int√©gration**: N tests

---

## Exemples JSON

**Exemple 1: Request valide**:
```json
{
  "field1": "value1",
  "field2": 123
}
```

**Exemple 2: Response succ√®s**:
```json
{
  "status": "success",
  "data": {
    "result": "value"
  }
}
```

**Exemple 3: Error response**:
```json
{
  "status": "error",
  "detail": "Validation error message"
}
```

---

# ‚úÖ Crit√®res d'acceptation

## Crit√®res fonctionnels
1. **[Crit√®re fonctionnel 1]** : Description v√©rifiable (ex: endpoint retourne status code 200)
2. **[Crit√®re fonctionnel 2]** : Description quantifiable (ex: response time < 100ms au 99th percentile)
3. **[Crit√®re fonctionnel 3]** : Description testable (ex: format JSON conforme au sch√©ma Pydantic)
4. **[Crit√®re N...]** : Ajouter autant de crit√®res fonctionnels que n√©cessaire pour couvrir tous les comportements

## Crit√®res techniques
5. **[Crit√®re technique 1]** : Contrainte technique (ex: type safety strict avec Literal types)
6. **[Crit√®re technique 2]** : Architecture (ex: endpoint synchrone `def` pas `async def`)
7. **[Crit√®re technique 3]** : D√©pendances (ex: sans appel DB/API externe)
8. **[Crit√®re N...]** : Ajouter selon besoins de la story

## Crit√®res qualit√©
9. **[Crit√®re qualit√© 1]** : Coverage minimum (ex: ‚â•95% sur composants critiques)
10. **[Crit√®re qualit√© 2]** : Tests passent (ex: X tests unitaires + Y tests int√©gration tous verts)
11. **[Crit√®re qualit√© 3]** : Standards projet (ex: Ruff + Mypy + Type hints PEP 695)
12. **[Crit√®re N...]** : Documentation, conventions nommage, etc.

## Crit√®res production (si applicable)
13. **[Crit√®re production 1]** : D√©ploiement (ex: HEALTHCHECK Dockerfile configur√©)
14. **[Crit√®re production 2]** : Monitoring (ex: int√©gration plateforme observabilit√©)
15. **[Crit√®re N...]** : Scaling, error handling, logging structur√©, etc.

---

**üí° Note importante** : Le nombre de crit√®res varie selon la complexit√© de la story :
- Story simple (2 story points) : 8-12 crit√®res typiquement
- Story moyenne (5 story points) : 12-18 crit√®res
- Story complexe (8 story points) : 18-25+ crit√®res

**Principe SMART** : Chaque crit√®re doit √™tre **S**p√©cifique, **M**esurable, **A**tteignable, **R**elevant, **T**emporel.

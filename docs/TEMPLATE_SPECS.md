---
title: "Story X: [Nom story]"
scope: "specs"
category: "user-story"
epic: "Epic X: [Nom epic]"
story_points: 0
priority: "medium"  # low, medium, high, critical
status: "planned"   # planned, in_progress, completed, blocked
dependencies: []
date: YYYY-MM-DD
keywords: []
technologies: []
business_value: "[Valeur business 1-2 phrases]"
acceptance_criteria:
  - "[Crit√®re 1]"
  - "[Crit√®re 2]"
---

# Story X: [Nom story]

## üéØ Contexte Business

**Besoin utilisateur**:
- [D√©crire le besoin m√©tier concret]
- [Qui utilise cette feature ?]
- [Quel probl√®me r√©sout-elle ?]

**Contraintes m√©tier**:
- [Contrainte 1: limites techniques, budgets, SLA]
- [Contrainte 2]
- [Contrainte 3]

**Valeur business**:
- ‚úÖ [Valeur 1: qu'apporte cette story au client final ?]
- ‚úÖ [Valeur 2: feedback rapide, validation early, d√©risquage]
- ‚úÖ [Valeur 3: foundation pour stories futures]
- ‚úÖ [Valeur 4: m√©triques observables]

**M√©triques succ√®s**:
- [M√©trique 1: temps de r√©ponse, taux d'erreur, etc.]
- [M√©trique 2: adoption client, feedback qualitatif]
- [M√©trique 3: coverage tests, qualit√© code]

---

## üìã Sp√©cifications Techniques

### 1. [Composant 1]

**R√¥le**: [D√©crire responsabilit√© unique du composant]

**Interface**:
```python
class ComposantExemple:
    """Docstring 1 ligne."""

    def methode_principale(self, param: Type) -> ReturnType:
        """Docstring m√©thode."""
```

**Champs/Param√®tres**:

| Champ | Type | Description | Contraintes |
|-------|------|-------------|-------------|
| `field_name` | `str` | Description | min_length=2, max_length=100 |
| `field_number` | `int` | Description | ‚â• 0, ‚â§ 1000 |

**Comportement**:
- [Comportement normal]
- [Edge cases]
- [Erreurs lev√©es]

**Validations** (si Pydantic):
- `field_validator`: [Validation custom]
- `model_validator`: [Validation cross-field]

**Exemple**:
```python
# Exemple utilisation
exemple = ComposantExemple(param="value")
resultat = exemple.methode_principale(input_data)
```

### 2. [Composant 2]

[R√©p√©ter structure similaire pour chaque composant de la story]

---

## üß™ Tests

### Tests unitaires (TDD)

**Format recommand√©: AAA (Arrange/Act/Assert)**

#### [Composant 1] (X tests)

| # | Nom test | Input | Output attendu | V√©rification |
|---|----------|-------|----------------|--------------|
| 1 | `test_composant_valid_input` | `{"key": "value"}` | `result.success == True` | V√©rifie comportement nominal |
| 2 | `test_composant_edge_case` | `{"key": ""}` | `ValidationError` | V√©rifie validation edge case |
| 3 | `test_composant_async` | `await call()` | `result` not None | V√©rifie fonction async |

**Exemple code test AAA**:
```python
def test_composant_valid_input():
    # Arrange: Setup initial state
    input_data = {"key": "value"}

    # Act: Execute function under test
    result = composant_fonction(input_data)

    # Assert: Verify expected outcome
    assert result.success is True
    assert result.data == expected_data
```

#### [Composant 2] (Y tests)

[R√©p√©ter tableau tests + exemple pour chaque composant]

**Total tests unitaires**: X + Y = Z tests

---

### Tests int√©gration

**Format recommand√©: Given/When/Then (BDD)**

**End-to-end** (N tests):

| # | Sc√©nario | Pr√©requis | Action | R√©sultat attendu |
|---|----------|-----------|--------|-------------------|
| 1 | `test_integration_happy_path` | App running | POST /endpoint | 200 + JSON valide |
| 2 | `test_integration_validation_error` | App running | POST data invalide | 400 + error message |
| 3 | `test_integration_edge_case` | State X | Action Y | Result Z |

**Exemple code test Given/When/Then**:
```python
def test_integration_happy_path():
    # Given: Initial state and preconditions
    client = TestClient(app)
    request_data = {
        "field": "value"
    }

    # When: Execute action
    response = client.post("/endpoint", json=request_data)

    # Then: Verify expected outcome
    assert response.status_code == 200
    data = response.json()
    assert "expected_field" in data
    assert data["expected_field"] == expected_value
```

**Total tests int√©gration**: N tests

---

### Exemples JSON

**Exemple 1: Request valide**:
```json
{
  "field1": "value1",
  "field2": 123
}
```

**Exemple 2: Response succ√®s**:
```json
{
  "status": "success",
  "data": {
    "result": "value"
  }
}
```

**Exemple 3: Error response**:
```json
{
  "status": "error",
  "detail": "Validation error message"
}
```

---

## ‚úÖ Crit√®res d'acceptation

**Phase 4 (Specs)**:
- [ ] Sp√©cifications techniques compl√®tes (tous composants)
- [ ] Tests unitaires list√©s (tous sc√©narios couverts)
- [ ] Tests int√©gration list√©s
- [ ] Exemples JSON fournis

**Phase 5 (Impl√©mentation TDD)**:
- [ ] **TDD Phase 1**: Tests unitaires [Composant 1] √©crits
- [ ] **TDD Phase 1**: [Composant 1] impl√©ment√© ‚Üí tests passent ‚úÖ
- [ ] **TDD Phase 2**: Tests unitaires [Composant 2] √©crits
- [ ] **TDD Phase 2**: [Composant 2] impl√©ment√© ‚Üí tests passent ‚úÖ
- [ ] **Tests int√©gration**: N tests end-to-end √©crits
- [ ] **Tests int√©gration**: Tous tests int√©gration passent ‚úÖ
- [ ] **Validation manuelle**: Test curl/Postman fonctionne
- [ ] **Quality checks**: Ruff lint + format: 0 erreurs
- [ ] **Quality checks**: Mypy strict: 0 erreurs
- [ ] **Coverage**: ‚â• 80% sur composants de cette story

**Documentation**:
- [ ] Docstrings 1 ligne (90% des fonctions)
- [ ] OpenAPI docs auto-g√©n√©r√©es (si route API)
- [ ] Logs structur√©s ajout√©s (si applicable)

---

## üìù Notes d'impl√©mentation

**D√©pendances**:
- [Story X]: [Pourquoi d√©pendance, quel composant n√©cessaire]
- [Story Y]: [Idem]

**Ordre TDD recommand√©**:
1. [Composant 1]: Foundation, pas de d√©pendances
2. [Composant 2]: D√©pend Composant 1
3. [Composant 3]: D√©pend Composants 1 + 2
4. Tests int√©gration: Valide assemblage

**Fichiers cr√©√©s/modifi√©s**:
- `app/[module]/[composant1].py`: [R√¥le]
- `app/[module]/[composant2].py`: [R√¥le]
- `tests/unit/test_[composant1].py`: X tests
- `tests/unit/test_[composant2].py`: Y tests
- `tests/integration/test_[feature].py`: N tests

**Commandes d√©veloppement**:
```bash
# Lancer tests unitaires story
pytest tests/unit/test_[composant1].py tests/unit/test_[composant2].py -v

# Lancer tests int√©gration story
pytest tests/integration/test_[feature].py -v

# Quality checks
ruff check . --fix && ruff format . && mypy app/

# Coverage story
pytest --cov=app/[module] --cov-report=term-missing
```

**Commit message** (apr√®s impl√©mentation compl√®te):
```bash
git commit -m "feat([scope]): [description courte feature]

- Implement [Composant 1] with [d√©tail important]
- Implement [Composant 2] with [d√©tail important]
- Add X unit tests + N integration tests
- Coverage: Z% on [module]

Closes #[issue-number] (si applicable)"
```

**Temps estim√©**:
- Specs (Phase 4): [X] heures
- Impl√©mentation TDD (Phase 5): [Y] heures
- Total: [X+Y] heures (~[story_points] story points)

---

**Template version**: 1.0
**Last updated**: 2025-01-18

---
title: "Story 7: Retry Logic avec Tenacity"
epic: "Epic 3: Production Ready"
story_points: 5
dependencies: ["epic-2/story-4", "epic-2/story-5", "epic-2/story-6"]
date: "2025-11-19"
keywords: ["tenacity", "retry", "exponential-backoff", "jitter", "error-handling", "resilience", "async", "before-sleep", "logging", "production-ready"]
scope: ["specs"]
technologies: ["tenacity", "asyncio", "python"]
---

# üéØ Contexte Business

## Besoin utilisateur

- **Robustesse production garantie** : Utilisateurs finaux attendent recherches vols abouties m√™me si Google Flights/Decodo subissent erreurs temporaires (timeouts r√©seau, rate limiting 429, erreurs serveur 5xx)
- **SLA minimum viable** : Taux de succ√®s global recherche ‚â•85% (target production) n√©cessite retry automatique intelligent sur erreurs r√©cup√©rables (erreurs network, proxies instables, captchas temporaires)
- **Exp√©rience utilisateur fluide** : Retry transparent invisible pour l'utilisateur final, pas de timeout brutal apr√®s premi√®re erreur, feedback progressif via logs monitoring
- **D√©cision business data-driven** : M√©triques retry observables (nombre tentatives, temps ajout√© par retry, taux succ√®s apr√®s retry) pour optimiser configuration production

## Contraintes m√©tier

- **Co√ªts bandwidth Decodo limit√©s** : Chaque retry = nouvelle requ√™te HTTP factur√©e au GB ($2.60-3.50/GB), n√©cessite limiter nombre max tentatives (3-5 recommand√©) pour √©viter explosion co√ªts sur erreurs persistantes
- **Timeout total acceptable** : Recherche multi-destinations doit compl√©ter en <60 secondes au p95 m√™me avec retry logic (√©vite frustration utilisateur), n√©cessite exponential backoff optimis√© (wait time min 4s, max 60s total)
- **Pas de retry sur erreurs client** : Erreurs 4xx (ValidationError, ParsingError, 404) non-retryables car probl√®me logique application pas transient error, retry uniquement sur 5xx/network/captcha
- **Thundering herd prevention** : Retry simultan√© de multiples requ√™tes peut surcharger Google Flights, n√©cessite jitter randomness pour distribuer charges retry dans le temps
- **Observabilit√© production** : Logs structur√©s retry obligatoires pour monitoring (attempt_number, exception type, wait time, proxy rotated) sans exposer secrets (masquer credentials proxies)

## Valeur business

- **R√©duction √©checs recherche quantifiable** : Retry logic augmente taux succ√®s crawl de 60-70% (sans retry) √† 85-90% (avec retry + rotation IP), √©conomie ~100-200‚Ç¨ co√ªts support/client par mois
- **SLA production garantis** : Permet promettre uptime API ‚â•99% m√™me si Google Flights instable (retry masque erreurs temporaires 5xx, timeouts r√©seau)
- **Foundation resilience scalable** : Patterns Tenacity retry r√©utilisables pour futures int√©grations externes (APIs tierces, webhooks, database queries si post-MVP), gain v√©locit√© 30-40%
- **M√©triques observables actionables** : Before_sleep callback fournit insights temps r√©el : retry patterns populaires, proxies d√©faillants identifi√©s, configuration exponential backoff optimisable

## M√©triques succ√®s

- **Taux retry d√©clench√©** : 15-25% de requ√™tes n√©cessitent ‚â•1 retry (baseline production attendue avec proxies + Google rate limiting)
- **Taux succ√®s apr√®s retry** : ‚â•90% de requ√™tes retries aboutissent avec succ√®s (retry logic efficace sur erreurs transient)
- **Temps ajout√© par retry** : M√©diane <8 secondes par retry (exponential backoff 4s-8s-16s optimal), p95 <30 secondes total retry time
- **√âconomie √©checs √©vit√©s** : Retry logic √©vite ~200-300 recherches √©chou√©es/mois (validation business ROI retry config)
- **Coverage tests** : ‚â•80% sur composants retry (RetryStrategy, CrawlerService int√©gration, before_sleep callback)

---

# üìã Sp√©cifications Techniques

## 1. RetryStrategy (Configuration Centralis√©e)

**R√¥le** : D√©finir la configuration Tenacity centralis√©e r√©utilisable pour tous les services n√©cessitant retry logic (CrawlerService, futurs services API tierces).

**Interface** :
```python
class RetryStrategy:
    """Configuration Tenacity centralis√©e pour retry logic production."""

    @staticmethod
    def get_crawler_retry() -> Retrying:
        """
        Retourne configuration retry optimis√©e CrawlerService.

        Returns:
            Retrying instance avec exponential backoff + jitter
        """
```

**Param√®tres Configuration** :

| Param√®tre | Type | Valeur Recommand√©e | Justification |
|-----------|------|-------------------|---------------|
| `stop` | `stop_after_attempt` | `3` | √âquilibre robustesse vs co√ªts bandwidth (3 tentatives = 2 retries max apr√®s √©chec initial) |
| `wait` | `wait_random_exponential` | `multiplier=2, min=4, max=60` | Exponential backoff √©vite spam, jitter √©vite thundering herd, min 4s √©vite blocages imm√©diats |
| `retry` | `retry_if_exception_type` | `(CaptchaDetectedError, NetworkError)` | Retry uniquement erreurs r√©cup√©rables (network, captcha temporaire), pas ValidationError/ParsingError |
| `before_sleep` | `before_sleep_log` callback | Custom callback avec logging structur√© | Observabilit√© retry attempts avec contexte m√©tier |
| `reraise` | `bool` | `True` | L√®ve exception finale si max retries atteint (caller g√®re error handling) |

**Comportement** :

- **Exponential backoff calculation** :
  - Tentative 1 : Attendre 0s (pas de retry encore)
  - Tentative 2 : Attendre 2^1 √ó 2 = 4s minimum (avec jitter random 0-4s additionnel)
  - Tentative 3 : Attendre 2^2 √ó 2 = 8s minimum (avec jitter random 0-8s additionnel)
  - Max wait time : 60s (plafonn√© pour √©viter timeouts >60s total)

- **Jitter randomness** :
  - `wait_random_exponential` ajoute random delay jusqu'√† 2^x √ó multiplier secondes
  - Exemple : tentative 2 ‚Üí random(0, 4s) ‚Üí wait total 0-4s
  - Exemple : tentative 3 ‚Üí random(0, 8s) ‚Üí wait total 0-8s
  - Pr√©vient thundering herd : requ√™tes simultan√©es retries distribu√©es dans le temps

- **Exception types retry** :
  - `CaptchaDetectedError` : Captcha d√©tect√© (reCAPTCHA/hCaptcha) ‚Üí retry avec rotation proxy
  - `NetworkError` : Timeout r√©seau, erreurs HTTP 5xx, connexion refus√©e ‚Üí retry avec backoff
  - ‚ùå Pas de retry : `ValidationError`, `ParsingError`, erreurs HTTP 4xx (erreurs client non-r√©cup√©rables)

**Erreurs lev√©es** :
- Exception finale reraise si max_retries atteint (type original : CaptchaDetectedError ou NetworkError)

**Logging structur√©** :
- DEBUG : Configuration retry cr√©√©e avec param√®tres (stop, wait strategy, retry conditions)

---

## 2. CrawlerService (Int√©gration Retry)

**R√¥le** : Int√©grer retry logic Tenacity dans m√©thode `crawl_google_flights` avec rotation automatique proxies et logging before_sleep callback.

**Interface** :
```python
class CrawlerService:
    """Service crawling Google Flights avec retry logic Tenacity."""

    @retry(**RetryStrategy.get_crawler_retry())
    async def crawl_google_flights(
        self,
        url: str,
        *,
        use_proxy: bool = True
    ) -> CrawlResult:
        """
        Crawl URL Google Flights avec retry automatique.

        Raises:
            CaptchaDetectedError: Si captcha d√©tect√© apr√®s max_retries
            NetworkError: Si erreur r√©seau persistante apr√®s max_retries
        """
```

**Comportement Retry Int√©gr√©** :

**Sc√©nario 1 : Crawl r√©ussi d√®s premi√®re tentative** :
1. Appeler `crawler.arun(url)` avec proxy actuel
2. V√©rifier status code 200 + absence captcha
3. Retourner CrawlResult directement (aucun retry n√©cessaire)

**Sc√©nario 2 : CaptchaDetectedError ‚Üí Retry avec rotation proxy** :
1. Tentative 1 : Captcha d√©tect√© ‚Üí l√®ve `CaptchaDetectedError`
2. Before_sleep callback : Logger WARNING avec contexte (attempt 1/3, exception type, wait time 4s, proxy utilis√©)
3. **Rotation proxy** : Appeler `proxy_service.get_next_proxy()` pour obtenir nouvelle IP
4. Attendre exponential backoff : ~4s avec jitter
5. Tentative 2 : Retry avec nouveau proxy
6. Si succ√®s ‚Üí retourner CrawlResult
7. Si √©chec persistant apr√®s 3 tentatives ‚Üí l√®ve `CaptchaDetectedError` finale

**Sc√©nario 3 : NetworkError (5xx, timeout) ‚Üí Retry avec backoff** :
1. Tentative 1 : Timeout r√©seau ou status 500 ‚Üí l√®ve `NetworkError`
2. Before_sleep callback : Logger WARNING avec contexte (attempt 1/3, exception NetworkError, wait time 4s)
3. **Rotation proxy optionnelle** : Si erreur 429 (rate limiting) ‚Üí rotation proxy, sinon m√™me proxy
4. Attendre exponential backoff : ~4s avec jitter
5. Tentative 2 : Retry
6. Si succ√®s ‚Üí retourner CrawlResult
7. Si √©chec persistant apr√®s 3 tentatives ‚Üí l√®ve `NetworkError` finale

**Sc√©nario 4 : ValidationError ‚Üí Pas de retry** :
1. Tentative 1 : URL invalide, param√®tres incorrects ‚Üí l√®ve `ValidationError`
2. Exception propag√©e imm√©diatement (pas de retry)
3. Caller g√®re erreur (HTTP 400 retourn√© √† client)

**Edge cases** :
- **Max retries atteint** : L√®ve exception finale avec attribut `attempts=3` pour observabilit√©
- **Before_sleep callback √©choue** : Ne doit jamais bloquer retry logic (try/except autour logging)
- **Proxy rotation √©choue** : Fallback m√™me proxy si pool √©puis√©, logger ERROR

**Logging structur√©** :
- INFO : D√©but crawl avec URL et proxy
- WARNING : Retry d√©clench√© (attempt N/max, exception type, wait time, proxy rotated)
- ERROR : Max retries atteint, crawl d√©finitivement √©chou√©
- DEBUG : Proxy rotation effectu√©e, nouvelle IP utilis√©e

---

## 3. Error Handling Diff√©renci√©

**R√¥le** : Mapper erreurs HTTP et exceptions custom vers strat√©gies retry appropri√©es selon type erreur (transient vs permanent).

**Mapping Erreurs ‚Üí Strat√©gie Retry** :

| Code/Exception | Type Erreur | Strat√©gie Retry | Rotation Proxy | Justification |
|----------------|-------------|----------------|----------------|---------------|
| **5xx (500, 502, 503, 504)** | Serveur temporaire | ‚úÖ Retry avec exponential backoff | üü° Optionnel | Erreur serveur Google transient, retry peut aboutir |
| **429 Rate Limiting** | Trop de requ√™tes | ‚úÖ Retry avec backoff + rotation proxy | ‚úÖ Obligatoire | Changement IP contourne rate limit IP-based |
| **403 Forbidden** | Blocage IP | ‚úÖ Retry avec rotation proxy imm√©diate | ‚úÖ Obligatoire | IP blacklist√©e, changement IP obligatoire |
| **Timeout r√©seau** | Connexion instable | ‚úÖ Retry avec backoff | üü° Optionnel | Network transient error, retry peut aboutir |
| **CaptchaDetectedError** | Captcha pr√©sent | ‚úÖ Retry avec rotation proxy | ‚úÖ Obligatoire | Changement IP peut √©viter captcha (fingerprint diff√©rent) |
| **404 Not Found** | Ressource inexistante | ‚ùå Pas de retry | ‚ùå Non | Erreur client permanente, retry inutile |
| **400 Bad Request** | Param√®tres invalides | ‚ùå Pas de retry | ‚ùå Non | Erreur client logique, n√©cessite correction code |
| **ValidationError** | Validation Pydantic | ‚ùå Pas de retry | ‚ùå Non | Erreur application logique, pas transient error |
| **ParsingError** | Parsing HTML √©chou√© | ‚ùå Pas de retry | ‚ùå Non | Structure HTML invalide, retry ne changera rien |

**Exceptions Custom** :

```python
class NetworkError(Exception):
    """Erreur r√©seau r√©cup√©rable via retry."""

    def __init__(self, url: str, status_code: int | None, attempts: int):
        """
        Args:
            url: URL concern√©e
            status_code: Code HTTP si disponible (None si timeout)
            attempts: Nombre tentatives effectu√©es
        """

class CaptchaDetectedError(Exception):
    """Captcha d√©tect√©, r√©cup√©rable via retry + rotation IP."""

    def __init__(self, url: str, captcha_type: str, proxy_used: str):
        """
        Args:
            url: URL concern√©e
            captcha_type: Type captcha (recaptcha_v2, recaptcha_v3, hcaptcha)
            proxy_used: Proxy ayant d√©clench√© captcha (format masqu√©)
        """
```

**Logging par Type Erreur** :

- **5xx/Timeout** : `WARNING - Network error detected, retrying... (attempt X/3, status: 503, wait: 4s)`
- **429/403** : `WARNING - Rate limit detected, rotating proxy... (attempt X/3, new_proxy: customer-XXX-FR-2)`
- **CaptchaDetectedError** : `WARNING - Captcha detected (recaptcha_v2), rotating proxy... (attempt X/3, proxy: customer-XXX-FR-1)`
- **ValidationError** : `ERROR - Validation failed, no retry (url: ..., error: ...)`
- **Max retries** : `ERROR - Max retries exceeded (3 attempts), operation failed (last_exception: NetworkError, url: ...)`

---

## 4. Before_Sleep Callback (Logging Retry Attempts)

**R√¥le** : Logger contexte complet de chaque retry attempt via callback Tenacity `before_sleep` pour observabilit√© production.

**Interface** :
```python
def log_retry_attempt(retry_state: RetryCallState) -> None:
    """
    Callback Tenacity before_sleep pour logging structur√© retry attempts.

    Args:
        retry_state: √âtat retry fourni par Tenacity
    """
```

**Param√®tres Callback** :

| Param√®tre RetryCallState | Type | Description | Utilisation |
|--------------------------|------|-------------|-------------|
| `attempt_number` | `int` | Num√©ro tentative actuelle (1-indexed) | Logger "attempt X/max_attempts" |
| `outcome.exception()` | `Exception` | Exception lev√©e par tentative pr√©c√©dente | Extraire type exception (CaptchaDetectedError, NetworkError) |
| `next_action.sleep` | `float` | Temps attente avant prochaine tentative (secondes) | Logger "wait_time_seconds" |
| `fn` | `Callable` | Fonction retry√©e (ex: `crawl_google_flights`) | Extraire nom fonction pour contexte |
| `args` / `kwargs` | Tuple/Dict | Arguments fonction retry√©e | Extraire URL crawl√©e |

**Extraction Contexte** :

```python
def log_retry_attempt(retry_state: RetryCallState) -> None:
    """Callback before_sleep avec extraction contexte complet."""
    # Extraire infos de base
    attempt_number = retry_state.attempt_number
    exception = retry_state.outcome.exception()
    wait_time = retry_state.next_action.sleep

    # Extraire URL depuis args (premier arg de crawl_google_flights)
    url = retry_state.args[0] if retry_state.args else "unknown"

    # Extraire proxy utilis√© si disponible (depuis service instance)
    proxy_used = getattr(retry_state.args[0], 'current_proxy', 'unknown') if retry_state.args else 'unknown'

    # Calculer attempts restants
    max_attempts = 3  # Depuis RetryStrategy configuration
    attempts_remaining = max_attempts - attempt_number

    # Logging JSON structur√©
    logger.warning(
        "Retry attempt triggered",
        extra={
            "url": url,
            "proxy_used": proxy_used,
            "exception_type": type(exception).__name__,
            "exception_message": str(exception),
            "attempt_number": attempt_number,
            "attempts_remaining": attempts_remaining,
            "wait_time_seconds": round(wait_time, 2),
            "next_retry_at": (datetime.now() + timedelta(seconds=wait_time)).isoformat()
        }
    )
```

**Logging JSON Output Exemple** :

```json
{
  "timestamp": "2025-11-19T14:23:45Z",
  "level": "WARNING",
  "message": "Retry attempt triggered",
  "url": "https://www.google.com/travel/flights?...",
  "proxy_used": "customer-XXX-country-FR-1",
  "exception_type": "CaptchaDetectedError",
  "exception_message": "reCAPTCHA v2 detected",
  "attempt_number": 1,
  "attempts_remaining": 2,
  "wait_time_seconds": 4.23,
  "next_retry_at": "2025-11-19T14:23:49Z"
}
```

**Edge cases** :
- **Exception extraction √©choue** : Fallback `exception_type: "UnknownError"`, logger DEBUG warning
- **URL extraction √©choue** : Fallback `url: "unknown"`, ne doit jamais bloquer retry
- **Callback l√®ve exception** : Try/except global autour logging, ne jamais bloquer retry logic

**Logging structur√©** :
- WARNING : Chaque retry attempt avec contexte complet
- DEBUG : Callback appel√© avec success
- ERROR : Callback √©choue (exception logg√©e mais retry continue)

---

# üß™ Tests

## Tests unitaires (TDD)

**Format recommand√© : AAA (Arrange/Act/Assert)**

### RetryStrategy (8 tests)

| # | Nom test | Sc√©nario | Input | Output attendu | V√©rification |
|---|----------|----------|-------|----------------|--------------|
| 1 | `test_retry_on_network_error` | Retry d√©clench√© sur NetworkError | Mock fonction levant `NetworkError` 2 fois puis succ√®s | Fonction appel√©e 3 fois (1 initiale + 2 retries), succ√®s final | V√©rifie retry automatique sur NetworkError |
| 2 | `test_retry_on_captcha_detected` | Retry d√©clench√© sur CaptchaDetectedError | Mock fonction levant `CaptchaDetectedError` 1 fois puis succ√®s | Fonction appel√©e 2 fois (1 initiale + 1 retry), succ√®s final | V√©rifie retry automatique sur CaptchaDetectedError |
| 3 | `test_no_retry_on_validation_error` | Pas de retry sur ValidationError | Mock fonction levant `ValidationError` | Exception propag√©e imm√©diatement, fonction appel√©e 1 seule fois | V√©rifie ValidationError non-retryable |
| 4 | `test_exponential_backoff_timing` | Wait time augmente exponentiellement | Mock fonction avec 3 √©checs NetworkError | Wait times ‚âà [4s, 8s, 16s] avec jitter (tol√©rance ¬±2s) | V√©rifie exponential backoff calculation |
| 5 | `test_max_retries_exceeded` | L√®ve exception finale si max retries atteint | Mock fonction levant `NetworkError` 4 fois (>max_attempts) | Exception `NetworkError` finale lev√©e apr√®s 3 tentatives | V√©rifie stop_after_attempt(3) |
| 6 | `test_jitter_randomness` | Jitter ajoute randomness wait time | Ex√©cuter retry 10 fois avec m√™me erreur | Wait times varient dans range [0, 4s] pour tentative 2 | V√©rifie wait_random_exponential randomness |
| 7 | `test_before_sleep_callback_logging` | Before_sleep callback appel√© √† chaque retry | Mock fonction avec 2 √©checs | Callback appel√© 2 fois avec `attempt_number=1` puis `attempt_number=2` | V√©rifie before_sleep int√©gration |
| 8 | `test_retry_success_after_failures` | Succ√®s apr√®s N √©checs < max_attempts | Mock fonction : 2 √©checs `NetworkError` puis succ√®s | Fonction appel√©e 3 fois, retour succ√®s final (pas d'exception) | V√©rifie retry aboutit si erreur transient |

### CrawlerService avec Retry (7 tests)

| # | Nom test | Sc√©nario | Input | Output attendu | V√©rification |
|---|----------|----------|-------|----------------|--------------|
| 9 | `test_crawl_success_no_retry` | Crawl r√©ussi premi√®re tentative, aucun retry | Mock `crawler.arun()` retourne HTML valide status 200 | `CrawlResult` retourn√©, `crawler.arun()` appel√© 1 fois | V√©rifie comportement nominal sans retry |
| 10 | `test_crawl_retry_on_500_error` | Retry automatique sur status 500 | Mock `crawler.arun()` : 1er appel status 500, 2√®me status 200 | `CrawlResult` succ√®s, `crawler.arun()` appel√© 2 fois, logs WARNING retry | V√©rifie retry sur 5xx errors |
| 11 | `test_crawl_retry_on_timeout` | Retry automatique sur timeout r√©seau | Mock `crawler.arun()` : 1er appel timeout exception, 2√®me succ√®s | `CrawlResult` succ√®s, `crawler.arun()` appel√© 2 fois | V√©rifie retry sur NetworkError timeout |
| 12 | `test_crawl_max_retries_network_error` | Max retries atteint, NetworkError finale | Mock `crawler.arun()` l√®ve `NetworkError` 4 fois (>max_attempts) | L√®ve `NetworkError` avec `attempts=3`, logs ERROR max retries | V√©rifie abandon apr√®s max_retries |
| 13 | `test_crawl_no_retry_on_404` | Pas de retry sur 404 Not Found | Mock `crawler.arun()` retourne status 404 | Exception propag√©e imm√©diatement (ou retour vide), aucun retry | V√©rifie erreur 4xx non-retryable |
| 14 | `test_crawl_before_sleep_logging` | Logging before_sleep callback chaque retry | Mock `crawler.arun()` : 2 √©checs `CaptchaDetectedError` puis succ√®s | Logs WARNING contiennent `attempt_number=1` et `attempt_number=2` avec contexte complet | V√©rifie before_sleep callback logging |
| 15 | `test_crawl_retry_with_proxy_rotation` | Rotation proxy √† chaque retry | Mock `crawler.arun()` : 1er appel captcha proxy1, 2√®me succ√®s proxy2 | `proxy_service.get_next_proxy()` appel√© 1 fois, logs montrent proxy rotation | V√©rifie int√©gration rotation proxy dans retry |

**Total tests unitaires** : 8 (RetryStrategy) + 7 (CrawlerService) = **15 tests**

---

## Tests int√©gration

**Format recommand√© : Given/When/Then (BDD)**

| # | Nom test | Pr√©requis (Given) | Action (When) | R√©sultat attendu (Then) |
|---|----------|-------------------|---------------|-------------------------|
| 1 | `test_integration_search_with_transient_errors` | Mock AsyncWebCrawler : 30% requ√™tes timeout puis succ√®s, 2 destinations √ó 3 dates = 6 combinaisons | Appeler `search_service.search_flights(SearchRequest)` | `SearchResponse` avec ‚â•4 r√©sultats (60% succ√®s imm√©diat + retry succ√®s), logs WARNING retry pour 2 combinaisons, temps total <30s |
| 2 | `test_integration_retry_exhaustion_graceful_degradation` | Mock AsyncWebCrawler : 40% requ√™tes l√®vent `NetworkError` persistant (4 tentatives), 3 destinations √ó 2 dates = 12 combinaisons | Appeler `search_service.search_flights(SearchRequest)` | `SearchResponse` avec ~7 r√©sultats (60% r√©ussis), logs ERROR max retries pour 5 combinaisons, pas d'exception bloquante |
| 3 | `test_integration_partial_retry_success` | Mock AsyncWebCrawler : 50% requ√™tes captcha 1√®re tentative puis succ√®s retry, 2 destinations √ó 5 dates = 10 combinaisons | Appeler `search_service.search_flights(SearchRequest)` | `SearchResponse` avec ~10 r√©sultats (100% succ√®s apr√®s retry), logs WARNING retry pour 5 combinaisons, proxy rotation visible dans logs |
| 4 | `test_integration_no_retry_on_client_errors` | Mock AsyncWebCrawler : 20% requ√™tes retournent status 404, 3 destinations √ó 3 dates = 18 combinaisons | Appeler `search_service.search_flights(SearchRequest)` | `SearchResponse` avec ~14 r√©sultats (80% succ√®s), 4 erreurs 404 propag√©es sans retry, logs montrent aucun retry pour 404 |
| 5 | `test_integration_end_to_end_retry_metrics_logging` | Mock AsyncWebCrawler : mix erreurs (20% timeout, 10% captcha, 70% succ√®s), 5 destinations √ó 2 dates = 20 combinaisons | Appeler `search_service.search_flights(SearchRequest)` | `SearchResponse` avec ~18 r√©sultats apr√®s retry, logs structur√©s contiennent m√©triques : total_retries, retry_rate, avg_wait_time, success_after_retry_rate |

**Total tests int√©gration** : 5 tests

---

**TOTAL TESTS** : 15 unitaires + 5 int√©gration = **20 tests**

---

## Exemples JSON

**Exemple 1 : CrawlResult apr√®s retry success**

```json
{
  "html": "<html>...Google Flights content...</html>",
  "success": true,
  "status_code": 200,
  "retry_metadata": {
    "attempts": 2,
    "total_wait_time_seconds": 4.23,
    "retry_reasons": ["CaptchaDetectedError"],
    "proxies_used": ["customer-XXX-FR-1", "customer-XXX-FR-2"]
  }
}
```

**Contexte** : Premi√®re tentative captcha d√©tect√© (proxy1), retry apr√®s 4.23s avec rotation proxy (proxy2), succ√®s.

---

**Exemple 2 : NetworkError apr√®s max retries**

```json
{
  "error": "NetworkError",
  "message": "Max retries exceeded (3 attempts) for URL",
  "details": {
    "url": "https://www.google.com/travel/flights?...",
    "attempts": 3,
    "last_status_code": 503,
    "total_wait_time_seconds": 28.47,
    "retry_history": [
      {"attempt": 1, "exception": "NetworkError", "status_code": 503, "wait_time": 4.12},
      {"attempt": 2, "exception": "NetworkError", "status_code": 503, "wait_time": 8.35},
      {"attempt": 3, "exception": "NetworkError", "status_code": 503, "wait_time": 16.00}
    ]
  }
}
```

**Contexte** : 3 tentatives √©chou√©es avec status 503 (service unavailable), exponential backoff respect√©, erreur finale apr√®s 28.47s total wait.

---

**Exemple 3 : Logging before_sleep callback avec contexte complet**

```json
{
  "timestamp": "2025-11-19T14:23:45.123Z",
  "level": "WARNING",
  "service": "CrawlerService",
  "message": "Retry attempt triggered",
  "url": "https://www.google.com/travel/flights?departure_id=CDG&arrival_id=NRT",
  "proxy_used": "customer-abc123-country-FR-1",
  "exception_type": "CaptchaDetectedError",
  "exception_message": "reCAPTCHA v2 detected",
  "captcha_type": "recaptcha_v2",
  "attempt_number": 1,
  "max_attempts": 3,
  "attempts_remaining": 2,
  "wait_time_seconds": 4.23,
  "next_retry_at": "2025-11-19T14:23:49.353Z",
  "exponential_backoff_multiplier": 2,
  "jitter_applied": true,
  "proxy_rotation_triggered": true,
  "new_proxy": "customer-abc123-country-FR-2"
}
```

**Contexte** : Before_sleep callback appel√© apr√®s 1√®re tentative √©chou√©e (captcha), logging JSON structur√© complet avec contexte m√©tier, proxy rotation effectu√©e, prochaine tentative dans 4.23 secondes.

---

# ‚úÖ Crit√®res d'acceptation

## Crit√®res fonctionnels

1. **Retry automatique sur erreurs r√©cup√©rables** : CrawlerService retry automatiquement sur `CaptchaDetectedError` et `NetworkError` avec exponential backoff (v√©rifi√© logs contiennent retry attempts)

2. **Pas de retry sur erreurs client** : Erreurs `ValidationError`, `ParsingError`, HTTP 4xx propag√©es imm√©diatement sans retry (v√©rifi√© fonction appel√©e 1 seule fois)

3. **Exponential backoff respect√©** : Wait times entre retries augmentent exponentiellement ~4s, ~8s, ~16s avec jitter al√©atoire (tol√©rance ¬±2s, v√©rifi√© via mock asyncio.sleep)

4. **Max retries limit√© √† 3 tentatives** : Retry logic arr√™te apr√®s 3 tentatives totales (1 initiale + 2 retries), l√®ve exception finale (v√©rifi√© assertion `attempts=3`)

5. **Jitter randomness appliqu√©** : Wait times varient al√©atoirement dans range [0, 2^x √ó multiplier] secondes pour √©viter thundering herd (v√©rifi√© statistiquement sur 10+ ex√©cutions)

6. **Rotation proxy √† chaque retry** : Si retry d√©clench√© ‚Üí `proxy_service.get_next_proxy()` appel√© pour obtenir nouvelle IP (v√©rifi√© mock spy proxy_service)

7. **Before_sleep callback logging** : Chaque retry attempt logge contexte complet : attempt_number, exception_type, wait_time, proxy_used (v√©rifi√© logs JSON structur√©s)

8. **Succ√®s apr√®s retry** : Si erreur transient r√©solu (ex: captcha dispara√Æt apr√®s rotation IP) ‚Üí retourne `CrawlResult` success sans lever exception (v√©rifi√© pas d'exception finale)

## Crit√®res techniques

9. **Type hints PEP 695** : RetryStrategy, before_sleep callback, exceptions custom annot√©s avec type hints modernes (`RetryCallState`, `Exception`, `float`)

10. **Async/Await coh√©rent** : Retry logic fonctionne avec fonctions async (`async def crawl_google_flights`), utilise `asyncio.sleep()` pour wait times (pas de blocage)

11. **Tenacity version 9.1.2+** : Utilise Tenacity avec support async natif, `wait_random_exponential`, `before_sleep` callback, `retry_if_exception_type` (v√©rifi√© pyproject.toml)

12. **Configuration centralis√©e RetryStrategy** : Classe RetryStrategy fournit m√©thode `get_crawler_retry()` retournant config Tenacity r√©utilisable (testable, modifiable sans toucher CrawlerService)

13. **D√©corateur @retry appliqu√©** : CrawlerService.crawl_google_flights d√©cor√© avec `@retry(**RetryStrategy.get_crawler_retry())` (syntaxe Tenacity standard)

14. **Exceptions custom typ√©es** : `NetworkError` et `CaptchaDetectedError` h√©ritent `Exception`, contiennent attributs contextuels (`url`, `status_code`, `attempts`, `captcha_type`, `proxy_used`)

15. **Before_sleep callback extraction contexte** : Callback extrait `retry_state.attempt_number`, `retry_state.outcome.exception()`, `retry_state.next_action.sleep`, URL depuis args (v√©rifi√© logging contient tous champs)

16. **Logging structur√© JSON complet** : Logs retry incluent contexte m√©tier : url, proxy_used, exception_type, attempt_number, attempts_remaining, wait_time_seconds, next_retry_at (format pythonjsonlogger)

17. **Reraise exception finale** : Si max retries atteint ‚Üí exception finale reraise avec contexte (type original pr√©serv√© : `CaptchaDetectedError` ou `NetworkError`)

18. **Mock asyncio.sleep pour tests** : Tests unitaires retry mockent `asyncio.sleep()` pour vitesse (pas attendre vraies secondes retry, v√©rifi√© ex√©cution tests <5s total)

## Crit√®res qualit√©

19. **Coverage ‚â•80%** : Tests unitaires + int√©gration couvrent minimum 80% code RetryStrategy, CrawlerService retry integration, before_sleep callback (pytest-cov)

20. **20 tests passent** : 15 tests unitaires (8 RetryStrategy + 7 CrawlerService) + 5 tests int√©gration tous verts (pytest -v)

21. **Ruff + Mypy passent** : `ruff check .` et `ruff format .` sans erreur, `mypy app/` strict mode sans erreur type

22. **Tests TDD format AAA** : Tests unitaires suivent strictement Arrange/Act/Assert, tableaux specs compl√©t√©s avec 6 colonnes (N¬∞, Nom, Sc√©nario, Input, Output, V√©rification)

23. **Tests int√©gration format Given/When/Then** : Tests int√©gration suivent BDD avec 5 colonnes (N¬∞, Nom, Pr√©requis, Action, R√©sultat), mocks AsyncWebCrawler/ProxyService configur√©s

24. **Docstrings 1 ligne** : RetryStrategy et before_sleep callback avec docstring descriptive, focus POURQUOI pas QUOI

25. **Aucun code production dans specs** : Ce document contient uniquement signatures, tableaux tests, descriptions comportements, exemples JSON, formules exponential backoff (pas d'impl√©mentation compl√®te)

26. **Commits conventional** : Story 7 committ√©e avec message `docs(specs): add story 7 specifications` conforme Conventional Commits

---

**Note importante** : Story moyenne complexit√© (5 story points) ‚Üí 26 crit√®res couvrent exhaustivement retry logic production-ready (8 fonctionnels), architecture Tenacity r√©utilisable (10 techniques), qualit√© tests TDD (8 qualit√©). R√©utilise CrawlerService/ProxyService existants (Story 4 et 6), ajoute layer resilience transparent.

**Principe SMART** : Chaque crit√®re est **S**p√©cifique (exponential backoff 4s-8s-16s), **M**esurable (20 tests passent, coverage ‚â•80%), **A**tteignable (Tenacity lib mature), **R**elevant (SLA production ‚â•85%), **T**emporel (MVP Phase 5, apr√®s CrawlerService/ProxyService d√©j√† impl√©ment√©s).

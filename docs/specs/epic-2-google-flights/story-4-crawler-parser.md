---
title: "Story 4: Crawler & Parser (Proof of Concept Google Flights 1 destination)"
epic: "Epic 2: Google Flights Integration"
story_points: 8
dependencies: ["story-1-health-check.md", "story-2-config-logging.md", "story-3-search-endpoint.md"]
date: "2025-11-19"
keywords: ["crawler", "parser", "crawl4ai", "google-flights", "scraping", "stealth-mode", "decodo-proxies", "jsoncssstrategy", "captcha-detection", "pydantic", "proof-of-concept"]
scope: ["specs"]
technologies: ["crawl4ai", "playwright", "pydantic", "decodo", "tenacity"]
---

# üéØ Contexte Business

## Besoin utilisateur

- **Proof of Concept technique** : Valider la faisabilit√© du scraping Google Flights pour une destination unique avant d'impl√©menter la logique multi-destinations complexe
- **D√©risquage early** : Identifier les blocages Google (captchas, rate limiting, anti-bot) d√®s la Story 4 plut√¥t qu'√† la Story 5-6 (√©conomie temps d√©veloppement)
- **Foundation scraping** : √âtablir les patterns r√©utilisables (CrawlerService + FlightParser) pour toutes les stories suivantes (5, 6, 7)
- **Validation stack technique** : Prouver que Crawl4AI + Decodo Proxies + JsonCssExtractionStrategy suffisent pour extraire des donn√©es structur√©es sans LLM

## Contraintes m√©tier

- **Anti-d√©tection Google Flights** : Google utilise Cloudflare/DataDome pour d√©tecter et bloquer les bots (n√©cessite stealth mode + proxies r√©sidentiels Decodo)
- **Captcha detection MVP** : Phase MVP = d√©tection uniquement (logging + retry avec rotation IP), pas de r√©solution automatique (2Captcha r√©serv√© Phase 7 optionnelle si taux blocage >5%)
- **Bandwidth Decodo limit√©** : Proxies r√©sidentiels factur√©s au GB ($2.60-3.50/GB selon volume), minimiser le nombre de requ√™tes et taille HTML t√©l√©charg√©
- **Pas de Database** : R√©sultats en m√©moire uniquement (pas de persistence), focus sur extraction et transformation donn√©es
- **Structure HTML Google Flights non document√©e** : S√©lecteurs CSS peuvent changer sans pr√©avis, n√©cessite monitoring et robustesse parsing

## Valeur business

- ‚úÖ **Validation technique early** : Confirme faisabilit√© scraping Google Flights avant investissement stories multi-destinations (d√©sengagement rapide si bloqu√©)
- ‚úÖ **Feedback qualit√© donn√©es** : Valide que les champs extraits (prix, compagnie, horaires, dur√©e, escales) sont suffisants et correctement format√©s pour ranking futur
- ‚úÖ **Foundation services r√©utilisables** : CrawlerService et FlightParser deviennent les building blocks des stories 5-6 (gain v√©locit√© 30-40%)
- ‚úÖ **M√©triques observables** : √âtablit baseline de performance (taux succ√®s crawl, temps r√©ponse, taux captcha d√©tect√©) pour optimisation continue
- ‚úÖ **R√©duction risque budget** : Valide co√ªts bandwidth Decodo r√©els vs estimations avant scaling multi-destinations

## M√©triques succ√®s

- **Taux succ√®s crawl** : ‚â•85% de requ√™tes Google Flights retournent HTML valide (status 200, pas de captcha)
- **Temps r√©ponse crawl** : ‚â§10 secondes par URL Google Flights (P95 percentile, incluant retry logic)
- **Taux captcha d√©tect√©** : ‚â§5% de requ√™tes bloqu√©es par reCAPTCHA/hCaptcha (target MVP)
- **Taux parsing r√©ussi** : ‚â•95% de HTML valides pars√©s avec succ√®s (minimum 5 vols extraits par recherche)
- **Qualit√© extraction** : 100% des champs obligatoires (price, airline, departure_time, arrival_time, duration) pr√©sents et valides selon sch√©ma Pydantic
- **Coverage tests** : ‚â•80% sur CrawlerService et FlightParser (unitaires + int√©gration)

---

# üìã Sp√©cifications Techniques

## 1. CrawlerService

**R√¥le** : Orchestrer le crawling Google Flights avec Crawl4AI, g√©rer le stealth mode, la rotation de proxies Decodo, et la d√©tection de captchas avec retry logic.

**Interface** :
```python
class CrawlerService:
    """Service de crawling Google Flights avec stealth mode et proxy rotation."""

    async def crawl_google_flights(
        self,
        url: str,
        *,
        use_proxy: bool = True,
        max_retries: int = 3
    ) -> CrawlResult:
        """
        Crawl une URL Google Flights avec retry logic et captcha detection.

        Raises:
            CaptchaDetectedError: Si captcha d√©tect√© apr√®s max_retries
            NetworkError: Si erreur r√©seau persistante apr√®s max_retries
        """
```

**Champs/Param√®tres** :

| Champ | Type | Description | Contraintes |
|-------|------|-------------|-------------|
| `url` | `str` | URL Google Flights compl√®te avec param√®tres query | Format `https://www.google.com/travel/flights?...` |
| `use_proxy` | `bool` | Active rotation proxies Decodo | Default `True`, `False` pour dev local |
| `max_retries` | `int` | Nombre maximum de tentatives avec rotation IP | Default `3`, range `1-5` |

**Comportement** :

- **Crawl nominal** :
  1. Initialise AsyncWebCrawler avec BrowserConfig (stealth mode, proxy Decodo si `use_proxy=True`)
  2. Ex√©cute `crawler.arun(url)` avec timeout 10s
  3. V√©rifie status code 200 et absence de captcha dans HTML
  4. Retourne CrawlResult avec `html`, `cleaned_html`, `success=True`

- **Edge cases** :
  - **Captcha d√©tect√©** : Si HTML contient patterns reCAPTCHA/hCaptcha ‚Üí L√®ve `CaptchaDetectedError` avec URL et proxy utilis√©
  - **Status code 403/429** : Rate limiting Google ‚Üí Retry avec rotation proxy et exponential backoff (4s, 8s, 16s)
  - **Timeout r√©seau** : Si `arun()` timeout apr√®s 10s ‚Üí Retry avec nouveau proxy
  - **Max retries d√©pass√©** : L√®ve `NetworkError` avec d√©tails des tentatives √©chou√©es

- **Erreurs lev√©es** :
  - `CaptchaDetectedError` : H√©rit√© de `Exception`, contient `url`, `proxy_used`, `captcha_type` (recaptcha_v2/v3/hcaptcha)
  - `NetworkError` : H√©rit√© de `Exception`, contient `url`, `status_code`, `attempts`

- **Logging structur√©** :
  - INFO : D√©but crawl avec URL et proxy utilis√©
  - WARNING : Captcha d√©tect√© (tentative N/max_retries) + rotation proxy
  - ERROR : Max retries atteint, crawl √©chou√©
  - DEBUG : HTML size, temps r√©ponse, status code

---

## 2. FlightParser

**R√¥le** : Extraire les donn√©es structur√©es de vols depuis le HTML Google Flights via JsonCssExtractionStrategy (sans LLM), valider avec Pydantic, et retourner une liste de mod√®les Flight.

**Interface** :
```python
class FlightParser:
    """Parser de vols Google Flights via JsonCssExtractionStrategy."""

    def parse(self, html: str) -> list[Flight]:
        """
        Extrait les vols depuis HTML Google Flights.

        Raises:
            ParsingError: Si aucun vol extrait ou HTML invalide
            ValidationError: Si validation Pydantic √©choue
        """
```

**Configuration Extraction CSS** :

La strat√©gie JsonCssExtractionStrategy doit extraire les champs suivants depuis le HTML Google Flights :

| Champ | Description | Type extraction | Contrainte |
|-------|-------------|-----------------|------------|
| `price` | Prix du vol en euros | Texte | √âl√©ment avec classe prix, extraire valeur num√©rique |
| `airline` | Nom de la compagnie a√©rienne | Texte | √âl√©ment compagnie, texte brut |
| `departure_time` | Heure de d√©part | Attribut datetime | Balise `<time>` d√©part, attribut `datetime` ISO 8601 |
| `arrival_time` | Heure d'arriv√©e | Attribut datetime | Balise `<time>` arriv√©e, attribut `datetime` ISO 8601 |
| `duration` | Dur√©e du vol | Texte | √âl√©ment dur√©e, format "Xh Ymin" |
| `stops` | Nombre d'escales | Texte | √âl√©ment escales, parser "Non-stop" ou "X stop(s)" |
| `departure_airport` | Code a√©roport d√©part | Texte | Premier √©l√©ment a√©roport dans route |
| `arrival_airport` | Code a√©roport arriv√©e | Texte | Dernier √©l√©ment a√©roport dans route |

**S√©lecteur de base** : Cibler les cartes de vols individuelles (conteneur principal r√©p√©t√© pour chaque vol)

**Note** : Les s√©lecteurs CSS exacts devront √™tre d√©termin√©s lors de l'impl√©mentation Phase 5 en inspectant le HTML r√©el de Google Flights (structure non document√©e, peut varier).

**Champs/Param√®tres** :

| Champ | Type | Description | Contraintes |
|-------|------|-------------|-------------|
| `html` | `str` | HTML brut Google Flights | Non vide, min_length > 1000 caract√®res |
| **Retour** | `List[Flight]` | Liste vols extraits et valid√©s | Minimum 1 vol, maximum 50 vols |

**Comportement** :

- **Extraction nominale** :
  1. Instancie JsonCssExtractionStrategy avec schema CSS ci-dessus
  2. Applique strat√©gie sur HTML avec `extraction_strategy.extract(html)`
  3. Transforme chaque √©l√©ment extrait en mod√®le Flight via Pydantic
  4. Valide automatiquement champs obligatoires (price, airline, departure_time, arrival_time)
  5. Retourne liste de Flight valid√©s

- **Edge cases** :
  - **Champs manquants** : Si prix/compagnie/horaires absents dans HTML ‚Üí Skip vol (log WARNING) et continue parsing vols suivants
  - **Prix invalide** : Si prix contient caract√®res non num√©riques (ex: "N/A") ‚Üí Skip vol
  - **HTML malformed** : Si baseSelector `.pIav2d` ne matche aucun √©l√©ment ‚Üí L√®ve `ParsingError("No flights found in HTML")`
  - **Liste vide apr√®s parsing** : Si aucun vol valide extrait ‚Üí L√®ve `ParsingError("Zero valid flights extracted")`

- **Validation Pydantic** :
  - `price` : `float`, valeur > 0
  - `airline` : `str`, min_length=2, max_length=100
  - `departure_time` : `datetime`, format ISO 8601 strict
  - `arrival_time` : `datetime`, format ISO 8601, apr√®s departure_time
  - `duration` : `str`, format "Xh Ymin" (ex: "10h 30min")
  - `stops` : `int | None`, valeur ‚â•0, None si "Non-stop"

- **Erreurs lev√©es** :
  - `ParsingError` : H√©rit√© de `Exception`, contient `html_size`, `flights_found`
  - `ValidationError` : Pydantic standard, contient d√©tails champs invalides

---

## 3. Mod√®le Flight (Pydantic)

**R√¥le** : Repr√©senter un vol extrait avec validation automatique des types et contraintes m√©tier.

**Interface** :
```python
class Flight(BaseModel):
    """Mod√®le Pydantic d'un vol extrait depuis Google Flights."""

    price: float
    airline: str
    departure_time: datetime
    arrival_time: datetime
    duration: str
    stops: int | None
    departure_airport: str | None
    arrival_airport: str | None
```

**Validations Pydantic** :

| Champ | Contrainte | Description |
|-------|-----------|-------------|
| `price` | `> 0` | Prix strictement positif (euros) |
| `airline` | `min_length=2, max_length=100` | Nom compagnie valide |
| `departure_time` | Format ISO 8601 | Datetime valide |
| `arrival_time` | Format ISO 8601 + apr√®s `departure_time` | Coh√©rence temporelle |
| `duration` | Pattern `"Xh Ymin"` | Format dur√©e strict (ex: "10h 30min") |
| `stops` | `‚â• 0` ou `None` | Nombre escales valide |
| `departure_airport` | `max_length=10` | Code IATA/ICAO |
| `arrival_airport` | `max_length=10` | Code IATA/ICAO |

**Validation cross-champs** : La m√©thode de validation doit v√©rifier que `arrival_time` est post√©rieur √† `departure_time` (coh√©rence temporelle du vol).

---

# üß™ Tests

## Tests unitaires (TDD)

**Format recommand√© : AAA (Arrange/Act/Assert)**

### CrawlerService (10 tests)

| # | Nom test | Sc√©nario | Input | Output attendu | V√©rification |
|---|----------|----------|-------|----------------|--------------|
| 1 | `test_crawl_success_without_proxy` | Crawl r√©ussi sans proxy (dev mode) | `url="https://google.com/travel/flights?..."`, `use_proxy=False` | `result.success == True`, `result.html` non vide | V√©rifie comportement nominal sans proxy |
| 2 | `test_crawl_success_with_proxy` | Crawl r√©ussi avec proxy Decodo | `url=URL_GOOGLE_FLIGHTS`, `use_proxy=True` | `result.success == True`, proxy utilis√© logg√© | V√©rifie configuration proxy Decodo |
| 3 | `test_crawl_recaptcha_v2_detection` | HTML contient reCAPTCHA v2 | Mock HTML avec `<div class="g-recaptcha">` | L√®ve `CaptchaDetectedError`, `captcha_type="recaptcha_v2"` | V√©rifie d√©tection pattern reCAPTCHA |
| 4 | `test_crawl_hcaptcha_detection` | HTML contient hCaptcha | Mock HTML avec `<div class="h-captcha">` | L√®ve `CaptchaDetectedError`, `captcha_type="hcaptcha"` | V√©rifie d√©tection pattern hCaptcha |
| 5 | `test_crawl_retry_on_captcha` | Captcha d√©tect√©, retry avec rotation proxy | 1√®re tentative captcha, 2√®me succ√®s | `result.success == True`, 2 proxies diff√©rents utilis√©s | V√©rifie retry logic avec rotation IP |
| 6 | `test_crawl_max_retries_exceeded` | Max retries atteint, tous captcha | 3 tentatives, toutes avec captcha | L√®ve `CaptchaDetectedError` final | V√©rifie abandon apr√®s max_retries |
| 7 | `test_crawl_network_timeout` | Timeout r√©seau AsyncWebCrawler | Mock `arun()` timeout apr√®s 10s | L√®ve `NetworkError`, `status_code=None` | V√©rifie gestion timeout |
| 8 | `test_crawl_status_403_retry` | Status code 403 (rate limiting) | Mock response status 403 | Retry avec exponential backoff 4s, 8s, 16s | V√©rifie retry logic sur 403 |
| 9 | `test_crawl_stealth_mode_enabled` | BrowserConfig avec stealth mode actif | `enable_stealth=True` dans config | `result.success == True`, stealth mode logg√© | V√©rifie activation stealth mode |
| 10 | `test_crawl_structured_logging` | Logging structur√© avec contexte | Crawl avec URL et proxy | Logs contiennent `url`, `proxy_used`, `status_code`, `html_size` | V√©rifie qualit√© logging JSON |

### FlightParser (10 tests)

| # | Nom test | Sc√©nario | Input | Output attendu | V√©rification |
|---|----------|----------|-------|----------------|--------------|
| 1 | `test_parse_valid_html_multiple_flights` | HTML valide avec 10 vols | Mock HTML avec 10 `.pIav2d` valides | `len(flights) == 10`, tous Flight valides | V√©rifie extraction nominale |
| 2 | `test_parse_flight_all_fields_present` | Vol avec tous champs renseign√©s | HTML avec price, airline, times, duration, stops, airports | `flight.price > 0`, tous champs non None | V√©rifie mapping complet champs |
| 3 | `test_parse_missing_price` | Vol sans prix | HTML avec airline mais sans `.FpEdX` | Vol skipp√©, log WARNING | V√©rifie robustesse champ obligatoire manquant |
| 4 | `test_parse_invalid_price_format` | Prix non num√©rique | HTML avec price="N/A" | Vol skipp√©, log WARNING | V√©rifie validation format prix |
| 5 | `test_parse_missing_airline` | Vol sans compagnie | HTML avec price mais sans `.sSHqwe` | Vol skipp√©, log WARNING | V√©rifie robustesse champ obligatoire manquant |
| 6 | `test_parse_invalid_datetime_format` | Horaire invalide | HTML avec `datetime="invalid"` | L√®ve `ValidationError` Pydantic | V√©rifie validation datetime strict |
| 7 | `test_parse_arrival_before_departure` | arrival_time < departure_time | HTML avec horaires incoh√©rents | L√®ve `ValidationError` via `field_validator` | V√©rifie validation coh√©rence temporelle |
| 8 | `test_parse_no_flights_found` | HTML sans `.pIav2d` | HTML Google Flights vide ou malformed | L√®ve `ParsingError("No flights found")` | V√©rifie gestion HTML invalide |
| 9 | `test_parse_stops_nonstop` | Vol direct | HTML avec "Non-stop" | `flight.stops == 0` | V√©rifie parsing "Non-stop" ‚Üí int 0 |
| 10 | `test_parse_stops_multiple` | Vol avec escales | HTML avec "2 stops" | `flight.stops == 2` | V√©rifie extraction nombre escales |

**Total tests unitaires** : 10 + 10 = 20 tests

---

## Tests int√©gration

**Format recommand√© : Given/When/Then (BDD)**

| # | Nom test | Pr√©requis (Given) | Action (When) | R√©sultat attendu (Then) |
|---|----------|-------------------|---------------|-------------------------|
| 1 | `test_integration_crawl_and_parse_success` | Mock AsyncWebCrawler avec HTML Google Flights valide (10 vols) | Crawl URL ‚Üí Parse HTML | `len(flights) == 10`, tous Flight valid√©s Pydantic, pas d'exception |
| 2 | `test_integration_crawl_captcha_retry_parse_success` | Mock AsyncWebCrawler : 1√®re tentative captcha, 2√®me HTML valide | Crawl avec retry ‚Üí Parse HTML 2√®me tentative | `len(flights) >= 5`, 2 proxies utilis√©s, logs WARNING captcha puis SUCCESS |
| 3 | `test_integration_crawl_max_retries_no_parse` | Mock AsyncWebCrawler : toutes tentatives retournent captcha | Crawl avec max_retries=3 | L√®ve `CaptchaDetectedError`, aucun parsing tent√©, 3 proxies diff√©rents utilis√©s |
| 4 | `test_integration_crawl_success_parse_zero_flights` | Mock AsyncWebCrawler avec HTML Google Flights vide (aucun `.pIav2d`) | Crawl URL ‚Üí Parse HTML vide | L√®ve `ParsingError("Zero valid flights extracted")`, crawl success mais parsing fail |

**Total tests int√©gration** : 4 tests

---

**TOTAL TESTS** : 20 unitaires + 4 int√©gration = **24 tests**

---

## Exemples JSON

**Exemple 1 : Flight extrait et valid√©**
```json
{
  "price": 1250.0,
  "airline": "Air France",
  "departure_time": "2025-06-01T10:30:00Z",
  "arrival_time": "2025-06-01T14:45:00Z",
  "duration": "10h 15min",
  "stops": 1,
  "departure_airport": "CDG",
  "arrival_airport": "NRT"
}
```

**Exemple 2 : Erreur CaptchaDetectedError**
```json
{
  "error": "CaptchaDetectedError",
  "message": "reCAPTCHA v2 detected after 3 retries",
  "details": {
    "url": "https://www.google.com/travel/flights?departure_id=CDG&arrival_id=NRT&outbound_date=2025-06-01",
    "captcha_type": "recaptcha_v2",
    "attempts": 3
  }
}
```

**Exemple 3 : ParsingError (aucun vol extrait)**
```json
{
  "error": "ParsingError",
  "message": "Zero valid flights extracted from HTML",
  "details": {
    "html_size": 123456,
    "base_selector_matches": 0,
    "reason": "No flight containers found in HTML"
  }
}
```

---

# üìä Observabilit√© & Monitoring

## Logging structur√©

Tous les logs doivent suivre le format JSON structur√© avec les champs suivants :

| Champ | Type | Description | Exemple |
|-------|------|-------------|---------|
| `timestamp` | ISO 8601 | Date et heure √©v√©nement | `"2025-11-19T10:30:45Z"` |
| `level` | String | Niveau log (DEBUG/INFO/WARNING/ERROR) | `"INFO"` |
| `service` | String | Service concern√© | `"CrawlerService"` |
| `message` | String | Message descriptif | `"Crawl successful"` |
| `url` | String | URL crawl√©e | URL Google Flights compl√®te |
| `proxy_used` | String (optionnel) | Proxy utilis√© (masqu√© si sensible) | Format customer g√©n√©rique |
| `status_code` | Integer | Code HTTP r√©ponse | `200`, `403`, `429` |
| `html_size` | Integer | Taille HTML en bytes | `245678` |
| `response_time_ms` | Integer | Temps r√©ponse en ms | `2345` |
| `stealth_mode` | Boolean | Stealth mode activ√© | `true` |
| `retry_attempt` | Integer | Num√©ro tentative (0 = premi√®re) | `0`, `1`, `2` |

**Note** : Secrets (mots de passe proxy, API keys) doivent √™tre masqu√©s dans les logs pour s√©curit√©.

---

# ‚úÖ Crit√®res d'acceptation

## Crit√®res fonctionnels

1. **Crawl Google Flights 1 destination r√©ussi** : CrawlerService crawle avec succ√®s une URL Google Flights aller-simple (Paris‚ÜíTokyo) et retourne CrawlResult avec HTML valide (status 200, ‚â•100KB HTML)

2. **Stealth mode actif** : BrowserConfig configur√© avec `enable_stealth=True`, v√©rifi√© dans logs structur√©s (champ `stealth_mode: true`)

3. **Captcha d√©tect√© et logg√©** : Si reCAPTCHA/hCaptcha pr√©sent dans HTML ‚Üí CaptchaDetectedError lev√©e avec `captcha_type` et `proxy_used` logg√©s en WARNING

4. **Retry logic avec rotation IP** : En cas de captcha/403/timeout ‚Üí retry avec exponential backoff (4s, 8s, 16s) et rotation proxies Decodo (3 proxies diff√©rents utilis√©s max)

5. **Parsing extrait minimum 5 vols** : FlightParser parse HTML Google Flights et retourne liste ‚â•5 Flight valid√©s Pydantic (champs obligatoires pr√©sents)

6. **Format Flight valide** : Chaque Flight contient `price > 0`, `airline` (2-100 caract√®res), `departure_time` et `arrival_time` (datetime ISO 8601), `duration` (format "Xh Ymin"), `stops` (int ‚â•0 ou None)

7. **Gestion champs manquants** : Si prix/compagnie/horaires absents ‚Üí vol skipp√© avec log WARNING, parsing continue pour vols suivants (pas d'exception bloquante)

8. **Erreurs explicites** : CaptchaDetectedError et ParsingError lev√©es avec messages descriptifs et contexte (URL, proxy, HTML size, attempts)

## Crit√®res techniques

9. **Type hints PEP 695** : Toutes signatures CrawlerService, FlightParser, Flight annot√©es avec type hints modernes (`list[Flight]`, `str | None`, `async def`)

10. **Async/Await coh√©rent** : CrawlerService.crawl_google_flights async, utilise `async with AsyncWebCrawler`, `await crawler.arun()`, pas de blocking IO

11. **Retry logic Tenacity** : Syst√®me de retry automatique avec maximum 3 tentatives, d√©lai exponentiel entre tentatives (4s, 8s, 16s jusqu'√† 60s max), d√©clenchement sur exceptions CaptchaDetectedError et NetworkError uniquement

12. **Pydantic v2** : Flight utilise BaseModel avec Field pour d√©finir contraintes de validation, validation cross-champs pour coh√©rence temporelle, configuration strict (extra='forbid')

13. **JsonCssExtractionStrategy** : Configuration extraction CSS avec s√©lecteur de base pour identifier conteneurs vols, 8 champs minimum √† extraire (types text/attribute selon besoin), pas de LLM

14. **Decodo Proxies configuration** : Authentification format customer avec cl√© API et ciblage pays (France), endpoint d√©di√©, syst√®me de rotation cyclique entre pool de proxies disponibles

15. **Logging structur√© JSON** : Tous logs incluent contexte m√©tier dans champs d√©di√©s : URL crawl√©e, proxy utilis√©, code status HTTP, taille HTML re√ßu, temps de r√©ponse en millisecondes, activation stealth mode, num√©ro tentative retry

16. **Exceptions custom** : CaptchaDetectedError et ParsingError h√©ritent de Exception standard Python, incluent attributs contextuels pour debugging : URL concern√©e, proxy utilis√©, type captcha d√©tect√©, taille HTML, nombre vols trouv√©s

## Crit√®res qualit√©

17. **Coverage ‚â•80%** : Tests unitaires + int√©gration couvrent minimum 80% du code de CrawlerService et FlightParser (pytest-cov)

18. **24 tests passent** : 20 tests unitaires (10 CrawlerService + 10 FlightParser) + 4 tests int√©gration tous verts (pytest -v)

19. **Ruff + Mypy passent** : `ruff check .` et `ruff format .` sans erreur, `mypy app/` strict mode sans erreur type

20. **Tests TDD format AAA** : Tests unitaires suivent strictement Arrange/Act/Assert, tableaux specs compl√©t√©s avec 6 colonnes (N¬∞, Nom, Sc√©nario, Input, Output, V√©rification)

21. **Tests int√©gration format Given/When/Then** : Tests int√©gration suivent BDD avec 5 colonnes (N¬∞, Nom, Pr√©requis, Action, R√©sultat), mocks AsyncWebCrawler configur√©s

22. **Docstrings 1 ligne** : CrawlerService et FlightParser avec docstring descriptive, m√©thodes principales document√©es, focus POURQUOI pas QUOI

23. **Aucun code production dans specs** : Ce document contient uniquement signatures, tableaux tests, descriptions comportements, exemples JSON (pas d'impl√©mentation compl√®te de m√©thodes)

24. **Commits conventional** : Story 4 committ√©e avec message `docs(specs): add story 4 specifications` conforme Conventional Commits

---

**üí° Note** : Cette story est un Proof of Concept (8 story points). Les 24 crit√®res couvrent faisabilit√© technique (crawl + parsing 1 destination), robustesse (captcha detection, retry logic), qualit√© (coverage, types, tests), et foundation r√©utilisable pour stories 5-6 (multi-destinations, search orchestration).

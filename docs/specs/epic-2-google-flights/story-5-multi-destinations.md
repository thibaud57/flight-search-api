---
title: "Story 5: Multi-destinations (CombinationGenerator)"
epic: "Epic 2: Google Flights Scraping"
story_points: 5
dependencies: ["story-4"]
date: "2025-18-11"
keywords: ["multi-destinations", "combination-generator", "multi-city", "permutations", "itertools", "asyncio-gather", "parallel-crawls", "orchestration", "ranking", "top-10"]
scope: ["specs"]
technologies: ["Python", "itertools", "asyncio", "FastAPI", "Pydantic v2"]
---

# ğŸ¯ Contexte Business

## Besoin utilisateur

### Persona 1: Product Owner
- Besoin de MVP complet multi-destinations pour dÃ©mo clients rÃ©els (2-10 villes)
- Validation technique orchestration crawls parallÃ¨les avec performance acceptable (<30s pour 3 destinations)
- Feedback early sur contraintes combinatoires (nombre crawls exponentiels vs performance)
- DÃ©monstration feature signature du produit (multi-city itinÃ©raires complexes)

### Persona 2: DÃ©veloppeur Backend (ce projet)
- Besoin d'orchestrer crawls multiples en parallÃ¨le avec asyncio.gather pour performance
- GÃ©nÃ©ration combinaisons intelligente avec itertools.product sans explosion combinatoire
- RÃ©utilisation services Story 4 (CrawlerService, FlightParser) sans modification
- ImplÃ©mentation ranking Top 10 global (agrÃ©gation rÃ©sultats multi-crawls)

### Persona 3: Utilisateur Final API
- Besoin de recherche multi-destinations rÃ©elle (ex: Paris â†’ Tokyo â†’ New York â†’ Paris)
- Top 10 meilleurs prix agrÃ©gÃ©s sur toutes combinaisons possibles
- RÃ©sultats triÃ©s par prix croissant avec itinÃ©raires multi-city cohÃ©rents
- Temps rÃ©ponse acceptable (<30s pour 3 destinations, <90s pour 5+ destinations)

## Contraintes mÃ©tier

### Contraintes fonctionnelles
- **2-10 destinations** : Validation Pydantic dÃ©jÃ  implÃ©mentÃ©e (Story 3), contrainte min 2 villes
- **Combinaisons exponentielles** : 3 destinations â†’ 6 combinaisons aller-retour, 5 destinations â†’ ~20 combinaisons
- **Limite Top 10 global** : AgrÃ©gation rÃ©sultats multi-crawls â†’ tri prix croissant â†’ 10 meilleurs
- **ItinÃ©raires aller-retour complets** : Chaque combinaison termine par ville origine (Paris â†’ Tokyo â†’ Paris)

### Contraintes techniques
- **Crawls parallÃ¨les obligatoires** : asyncio.gather pour exÃ©cution simultanÃ©e, timeout 30s par crawl
- **Gestion Ã©checs partiels** : Continue si 1+ crawls Ã©chouent (captcha, timeout), retourne rÃ©sultats disponibles
- **Pas de cache combinaisons** : GÃ©nÃ©ration dynamique Ã  chaque requÃªte (prÃ©paration optimisations Phase 6+)
- **URL multi_city_json format** : JSON segments encodÃ©s selon docs/references/google-flights.md

### Contraintes performance et coÃ»ts
- **Bandwidth Decodo** : N crawls parallÃ¨les = NÃ—500KB-2MB, optimiser nombre combinaisons si > 10
- **Timeout global** : Max 30-90s recherche complÃ¨te (dÃ©pend nb combinaisons)
- **Pas de retry dans cette story** : Retry logic Tenacity reportÃ© Story 6+
- **Type safety strict** : PEP 695, Mypy strict mode, asyncio types annotÃ©s

## Valeur business

- âœ… **MVP Feature Complet** : DÃ©mo multi-city fonctionnelle pour clients, diffÃ©renciation concurrents (feature unique)
- âœ… **Validation Performance Crawls ParallÃ¨les** : Proof of concept asyncio.gather sur cas rÃ©el, mesure temps rÃ©ponse
- âœ… **Foundation Scalable** : Architecture orchestration prÃªte pour optimisations Phase 6+ (caching, rate limiting)
- âœ… **Feedback Contraintes Combinatoires** : DonnÃ©es rÃ©elles pour dÃ©cision seuil max destinations (ex: limiter Ã  5 si >20 crawls)
- âœ… **RÃ©utilisation Services Story 4** : Aucune modification CrawlerService/FlightParser nÃ©cessaire, principe DRY

## MÃ©triques succÃ¨s

### MÃ©triques fonctionnelles
- **Recherche 3 destinations < 30s** : p95 temps rÃ©ponse â‰¤ 30 secondes (6 crawls parallÃ¨les)
- **Top 10 rÃ©sultats triÃ©s** : 100% responses retournent â‰¤10 FlightResult triÃ©s prix croissant
- **Combinaisons cohÃ©rentes** : 100% itinÃ©raires terminent par ville origine (validation aller-retour)
- **Handling Ã©checs partiels** : Si 2/6 crawls Ã©chouent, retourne 4 rÃ©sultats disponibles (pas d'erreur 500)

### MÃ©triques qualitÃ©
- **Coverage â‰¥ 80%** : pytest --cov=app atteint 80%+ sur CombinationGenerator, SearchService orchestration
- **21 tests passent** : 6 Generator + 8 Service + 3 Ranking + 4 intÃ©gration tous verts
- **Mypy strict mode** : 0 erreur de type
- **Ruff lint/format** : 0 erreur

### MÃ©triques production
- **Logs structurÃ©s combinaisons** : Chaque recherche loggÃ©e avec nb_combinations, crawls_success, crawls_failed, top_10_price_range
- **Monitoring temps crawls** : Log duration_ms par crawl pour identifier timeouts rÃ©currents
- **Taux Ã©checs crawls** : Calcul `crawls_failed / nb_combinations` pour dÃ©cision retry logic Phase 6+

---

# ğŸ“‹ SpÃ©cifications Techniques

## 1. CombinationGenerator

**RÃ´le** : Service gÃ©nÃ©rant toutes permutations multi-city aller-retour depuis liste destinations.

**Interface** :
```python
import itertools

class CombinationGenerator:
    """GÃ©nÃ¨re combinaisons multi-city aller-retour."""

    def generate_combinations(
        self,
        destinations: list[str],
        date_range: DateRange
    ) -> list[list[str]]:
        """GÃ©nÃ¨re toutes permutations multi-city aller-retour.

        Args:
            destinations: Liste villes (min 2)
            date_range: Plage dates recherche

        Returns:
            Liste combinaisons format [["Paris", "Tokyo", "Paris"], ...]

        Example:
            >>> gen = CombinationGenerator()
            >>> destinations = ["Paris", "Tokyo", "New York"]
            >>> date_range = DateRange(start="2025-06-01", end="2025-06-15")
            >>> combinations = gen.generate_combinations(destinations, date_range)
            >>> len(combinations)
            6
        """
```

**Algorithme avec itertools.product** :

```python
def generate_combinations(
    self,
    destinations: list[str],
    date_range: DateRange
) -> list[list[str]]:
    """GÃ©nÃ¨re combinaisons multi-city aller-retour."""
    if len(destinations) < 2:
        raise ValueError("destinations must contain at least 2 cities")

    origin = destinations[0]
    other_cities = destinations[1:]

    combinations = []
    for dest in other_cities:
        for intermediate in other_cities:
            if dest != intermediate:
                combinations.append([origin, dest, intermediate, origin])

    if len(combinations) > 10:
        combinations = combinations[:10]

    return combinations
```

**Note Algorithme** : Exemple simplifiÃ© ci-dessus gÃ©nÃ¨re combinaisons 4 villes. Pour gÃ©nÃ©ralisation N destinations, utiliser `itertools.product(destinations, repeat=2)` puis filtrer doublons et ajouter retour origine.

**RÃ¨gles mÃ©tier** :

1. **DÃ©duplication** : Ã‰viter combinaisons redondantes (Parisâ†’Tokyoâ†’Paris â‰  Tokyoâ†’Parisâ†’Tokyo car dates diffÃ©rentes)
2. **Limite max 10 combinaisons** : Si > 10 possibilitÃ©s, prioriser paires directes (origine â†’ destination_i â†’ origine)
3. **Dates utilisÃ©es** : ParamÃ¨tre `date_range` passÃ© pour construction URLs (pas utilisÃ© dans gÃ©nÃ©ration combinaisons)

**Exemple gÃ©nÃ©ration 3 destinations** :

Input:
```python
destinations = ["Paris", "Tokyo", "New York"]
date_range = DateRange(start="2025-06-01", end="2025-06-15")
```

Output:
```python
[
    ["Paris", "Tokyo", "Paris"],
    ["Paris", "New York", "Paris"],
    ["Paris", "Tokyo", "New York", "Paris"],
    ["Paris", "New York", "Tokyo", "Paris"],
    # ... 6 combinaisons totales
]
```

---

## 2. SearchService Orchestration Multi-Crawls

**RÃ´le** : Orchestrer gÃ©nÃ©ration combinaisons â†’ construction URLs multi-city â†’ crawls parallÃ¨les â†’ parsing â†’ ranking Top 10.

**Nouvelle signature (modification Story 3)** :
```python
from app.services.combination_generator import CombinationGenerator
from app.services.crawler_service import CrawlerService
from app.services.flight_parser import FlightParser

class SearchService:
    """Service orchestration recherche vols multi-city."""

    def __init__(
        self,
        combination_generator: CombinationGenerator,
        crawler_service: CrawlerService,
        flight_parser: FlightParser
    ) -> None:
        """Initialise SearchService avec dÃ©pendances injectÃ©es."""

    async def search_flights(self, request: SearchRequest) -> list[FlightResult]:
        """Recherche vols multi-city avec crawls parallÃ¨les.

        Args:
            request: SearchRequest avec destinations (2-10) et date_range

        Returns:
            Liste FlightResult Top 10 triÃ©e prix croissant

        Raises:
            ValueError: Si destinations < 2
            CrawlException: Si tous crawls Ã©chouent
        """
```

**Workflow orchestration (6 Ã©tapes)** :

1. **GÃ©nÃ©ration combinaisons** :
   ```python
   combinations = self.combination_generator.generate_combinations(
       destinations=request.destinations,
       date_range=request.date_range
   )
   logger.info("Combinations generated", extra={"nb_combinations": len(combinations)})
   ```

2. **Construction URLs multi-city** :
   ```python
   urls = [
       build_multi_city_url(combination=combo, date_range=request.date_range)
       for combo in combinations
   ]
   ```

3. **Crawls parallÃ¨les avec asyncio.gather** :
   ```python
   crawl_tasks = [
       self.crawler_service.crawl_google_flights(url)
       for url in urls
   ]
   crawl_results = await asyncio.gather(*crawl_tasks, return_exceptions=True)
   ```

4. **Filtrer Ã©checs + Parser HTML** :
   ```python
   parsed_flights = []
   for i, result in enumerate(crawl_results):
       if isinstance(result, Exception):
           logger.warning(
               "Crawl failed",
               extra={"url": urls[i], "error": str(result)}
           )
           continue

       flights = self.flight_parser.parse_flights(
           html=result,
           destinations=combinations[i]
       )
       parsed_flights.extend(flights)
   ```

5. **Ranking Top 10 prix croissant** :
   ```python
   top_10 = rank_flights_by_price(parsed_flights)
   ```

6. **Retour rÃ©sultats** :
   ```python
   logger.info(
       "Search completed",
       extra={
           "search_id": str(uuid.uuid4()),
           "nb_combinations": len(combinations),
           "crawls_success": sum(1 for r in crawl_results if not isinstance(r, Exception)),
           "crawls_failed": sum(1 for r in crawl_results if isinstance(r, Exception)),
           "total_flights_parsed": len(parsed_flights),
           "top_10_count": len(top_10),
           "price_range": f"{top_10[0].price}-{top_10[-1].price}" if top_10 else "N/A"
       }
   )
   return top_10
   ```

---

## 3. URL Construction Helper Multi-City

**RÃ´le** : Construire URL Google Flights multi-city avec paramÃ¨tre `multi_city_json`.

**Interface** :
```python
import json
from urllib.parse import urlencode

def build_multi_city_url(combination: list[str], date_range: DateRange) -> str:
    """Construit URL Google Flights multi-city avec segments JSON.

    Args:
        combination: Liste villes itinÃ©raire (ex: ["Paris", "Tokyo", "Paris"])
        date_range: Plage dates recherche

    Returns:
        URL Google Flights encodÃ©e avec multi_city_json

    Example:
        >>> combination = ["Paris", "Tokyo", "New York", "Paris"]
        >>> date_range = DateRange(start="2025-06-01", end="2025-06-15")
        >>> url = build_multi_city_url(combination, date_range)
        >>> print(url)
        https://www.google.com/travel/flights?flight_type=3&multi_city_json=%5B%7B%22departure_id%22%3A%22CDG%22...
    """
```

**Format JSON segments** :
```json
[
  {
    "departure_id": "CDG",
    "arrival_id": "NRT",
    "date": "2025-06-01"
  },
  {
    "departure_id": "NRT",
    "arrival_id": "JFK",
    "date": "2025-06-08"
  },
  {
    "departure_id": "JFK",
    "arrival_id": "CDG",
    "date": "2025-06-15"
  }
]
```

**ImplÃ©mentation** :
```python
from app.utils.iata_mapping import CITY_TO_IATA

def build_multi_city_url(combination: list[str], date_range: DateRange) -> str:
    """Construit URL multi-city avec segments JSON encodÃ©s."""
    segments = []
    num_segments = len(combination) - 1

    for i in range(num_segments):
        departure_city = combination[i]
        arrival_city = combination[i + 1]

        segment_date = date_range.start if i == 0 else date_range.end

        segments.append({
            "departure_id": CITY_TO_IATA.get(departure_city, departure_city),
            "arrival_id": CITY_TO_IATA.get(arrival_city, arrival_city),
            "date": segment_date
        })

    multi_city_json = json.dumps(segments)

    params = {
        "flight_type": "3",
        "multi_city_json": multi_city_json,
        "hl": "fr",
        "curr": "EUR"
    }

    base_url = "https://www.google.com/travel/flights"
    return f"{base_url}?{urlencode(params)}"
```

**Note URL Encoding** : `urlencode()` encode automatiquement JSON (`{` â†’ `%7B`, `"` â†’ `%22`).

---

## 4. Crawls ParallÃ¨les avec asyncio.gather

**Pattern asyncio.gather** :
```python
import asyncio

async def search_flights(self, request: SearchRequest) -> list[FlightResult]:
    """Recherche vols avec crawls parallÃ¨les."""
    urls = [...]

    crawl_tasks = [
        self.crawler_service.crawl_google_flights(url)
        for url in urls
    ]

    crawl_results = await asyncio.gather(*crawl_tasks, return_exceptions=True)

    for i, result in enumerate(crawl_results):
        if isinstance(result, Exception):
            logger.warning(
                "Crawl failed, continuing with other results",
                extra={
                    "url": urls[i],
                    "error_type": type(result).__name__,
                    "error_message": str(result)
                }
            )
            continue
```

**Gestion erreurs** :
- **`return_exceptions=True`** : Continue si 1+ crawls Ã©chouent, retourne Exception dans liste rÃ©sultats
- **Log WARNING** : Logger chaque Ã©chec crawl avec URL + error type + error message
- **Pas d'arrÃªt complet** : Continue traitement rÃ©sultats valides mÃªme si Ã©checs partiels

**Timeout global** :
- Timeout par crawl : 30s (CrawlerService config)
- Timeout global recherche : ~30-90s selon nombre combinaisons (3 destinations â‰ˆ 30s, 5+ destinations â‰ˆ 60-90s)

---

## 5. Top 10 Ranking

**RÃ´le** : Trier rÃ©sultats agrÃ©gÃ©s multi-crawls par prix croissant et limiter Ã  Top 10.

**Interface** :
```python
def rank_flights_by_price(flights: list[FlightResult]) -> list[FlightResult]:
    """Trie vols par prix croissant et limite Top 10.

    Args:
        flights: Liste FlightResult agrÃ©gÃ©e depuis multi-crawls

    Returns:
        Liste FlightResult Top 10 triÃ©e prix croissant

    Example:
        >>> flights = [
        ...     FlightResult(price=1500.00, ...),
        ...     FlightResult(price=1200.00, ...),
        ...     FlightResult(price=1800.00, ...)
        ... ]
        >>> top_10 = rank_flights_by_price(flights)
        >>> top_10[0].price
        1200.00
    """
    sorted_flights = sorted(flights, key=lambda f: f.price)
    return sorted_flights[:10]
```

**RÃ¨gles mÃ©tier ranking** :

1. **PrioritÃ© prix croissant** : Vol moins cher en premier (index 0)
2. **Ã‰galitÃ© prix** : Ordre arbitraire si prix identiques (pas de tri secondaire MVP)
3. **Devise EUR fixe** : Validation dÃ©jÃ  faite par FlightResult.currency (Literal["EUR", "USD"]), pas de conversion

**Edge cases** :
- Si `len(flights) == 0` â†’ Retourne `[]`
- Si `len(flights) < 10` â†’ Retourne tous rÃ©sultats disponibles triÃ©s
- Si `len(flights) > 10` â†’ Limite stricte Top 10 meilleurs prix

---

# ğŸ§ª Tests

## Tests unitaires (TDD)

**Format recommandÃ© : AAA (Arrange/Act/Assert)**

### CombinationGenerator (6 tests)

| # | Nom test | Input | Output attendu | VÃ©rification |
|---|----------|-------|----------------|--------------|
| 1 | `test_generate_combinations_3_destinations` | 3 destinations | 6 combinaisons aller-retour | VÃ©rifier `len(combinations) == 6` |
| 2 | `test_generate_combinations_2_destinations` | 2 destinations (min) | 1 combinaison aller-retour | VÃ©rifier `len(combinations) == 1` |
| 3 | `test_generate_combinations_respects_max_limit` | 10 destinations | Max 10 combinaisons | VÃ©rifier `len(combinations) <= 10` |
| 4 | `test_generate_combinations_includes_return_to_origin` | 3 destinations | Toutes combinaisons terminent par origine | VÃ©rifier `all(combo[-1] == origin)` |
| 5 | `test_generate_combinations_empty_destinations_raises_error` | `destinations=[]` | ValueError levÃ©e | VÃ©rifier exception message |
| 6 | `test_generate_combinations_date_range_used` | date_range fourni | Dates dans combinaisons = date_range | VÃ©rifier cohÃ©rence dates |

**Exemple code test AAA** :
```python
import pytest
from app.services.combination_generator import CombinationGenerator
from app.models.request import DateRange

def test_generate_combinations_3_destinations():
    # Arrange: Setup generator with 3 destinations
    generator = CombinationGenerator()
    destinations = ["Paris", "Tokyo", "New York"]
    date_range = DateRange(start="2025-06-01", end="2025-06-15")

    # Act: Generate combinations
    combinations = generator.generate_combinations(
        destinations=destinations,
        date_range=date_range
    )

    # Assert: Verify 6 combinations generated
    assert len(combinations) == 6
    assert all(isinstance(combo, list) for combo in combinations)

def test_generate_combinations_includes_return_to_origin():
    # Arrange: Setup generator
    generator = CombinationGenerator()
    destinations = ["Paris", "Tokyo", "New York"]
    date_range = DateRange(start="2025-06-01", end="2025-06-15")
    origin = destinations[0]

    # Act: Generate combinations
    combinations = generator.generate_combinations(
        destinations=destinations,
        date_range=date_range
    )

    # Assert: Verify all combinations return to origin
    assert all(combo[-1] == origin for combo in combinations)

def test_generate_combinations_empty_destinations_raises_error():
    # Arrange: Setup generator with empty destinations
    generator = CombinationGenerator()
    destinations = []
    date_range = DateRange(start="2025-06-01", end="2025-06-15")

    # Act & Assert: Verify ValueError raised
    with pytest.raises(ValueError) as exc_info:
        generator.generate_combinations(
            destinations=destinations,
            date_range=date_range
        )

    assert "at least 2 cities" in str(exc_info.value).lower()
```

**Total tests unitaires CombinationGenerator** : 6 tests

---

### SearchService Multi-City (8 tests)

| # | Nom test | Input | Output attendu | VÃ©rification |
|---|----------|-------|----------------|--------------|
| 1 | `test_search_service_generates_combinations` | SearchRequest 3 destinations | CombinationGenerator appelÃ© | VÃ©rifier `mock_generator.generate_combinations.called` |
| 2 | `test_search_service_crawls_all_urls` | 6 combinaisons | CrawlerService.crawl appelÃ© 6 fois | VÃ©rifier `mock_crawler.crawl.call_count == 6` |
| 3 | `test_search_service_parses_all_html` | 6 HTML results | FlightParser.parse appelÃ© 6 fois | VÃ©rifier `mock_parser.parse.call_count == 6` |
| 4 | `test_search_service_aggregates_results` | 3 rÃ©sultats par crawl | Liste agrÃ©gÃ©e 18 rÃ©sultats | VÃ©rifier `len(all_results) == 18` |
| 5 | `test_search_service_handles_crawl_failure` | 2/6 crawls Ã©chouent | Continue avec 4 rÃ©sultats | VÃ©rifier log WARNING + rÃ©sultats partiels |
| 6 | `test_search_service_returns_top_10` | 18 rÃ©sultats agrÃ©gÃ©s | Max 10 rÃ©sultats retournÃ©s | VÃ©rifier `len(results) == 10` |
| 7 | `test_search_service_async_execution` | Appel async | Service exÃ©cute sans blocage | VÃ©rifier fonction async fonctionne |
| 8 | `test_search_service_dependency_injection` | Mocks injectÃ©s | DÃ©pendances utilisÃ©es correctement | VÃ©rifier mocks appelÃ©s |

**Exemple code test AAA** :
```python
import pytest
from unittest.mock import AsyncMock, MagicMock
from app.services.search_service import SearchService
from app.models.request import SearchRequest, DateRange

@pytest.mark.asyncio
async def test_search_service_generates_combinations():
    # Arrange: Setup mocks
    mock_generator = MagicMock()
    mock_generator.generate_combinations.return_value = [
        ["Paris", "Tokyo", "Paris"],
        ["Paris", "New York", "Paris"]
    ]
    mock_crawler = AsyncMock()
    mock_parser = MagicMock()

    service = SearchService(
        combination_generator=mock_generator,
        crawler_service=mock_crawler,
        flight_parser=mock_parser
    )

    request = SearchRequest(
        destinations=["Paris", "Tokyo", "New York"],
        date_range=DateRange(start="2025-06-01", end="2025-06-15")
    )

    # Act: Call search_flights
    await service.search_flights(request)

    # Assert: Verify generator called
    mock_generator.generate_combinations.assert_called_once_with(
        destinations=request.destinations,
        date_range=request.date_range
    )

@pytest.mark.asyncio
async def test_search_service_handles_crawl_failure():
    # Arrange: Setup mocks with partial failures
    mock_generator = MagicMock()
    mock_generator.generate_combinations.return_value = [
        ["Paris", "Tokyo", "Paris"],
        ["Paris", "New York", "Paris"]
    ]

    mock_crawler = AsyncMock()
    mock_crawler.crawl_google_flights.side_effect = [
        "<html>Valid HTML</html>",
        Exception("Crawl timeout")
    ]

    mock_parser = MagicMock()
    mock_parser.parse_flights.return_value = [
        MagicMock(price=1200.00)
    ]

    service = SearchService(
        combination_generator=mock_generator,
        crawler_service=mock_crawler,
        flight_parser=mock_parser
    )

    request = SearchRequest(
        destinations=["Paris", "Tokyo", "New York"],
        date_range=DateRange(start="2025-06-01", end="2025-06-15")
    )

    # Act: Call search_flights
    results = await service.search_flights(request)

    # Assert: Verify partial results returned (1 success, 1 failure)
    assert len(results) >= 1
    mock_crawler.crawl_google_flights.assert_called()
```

**Total tests unitaires SearchService** : 8 tests

---

### Ranking (3 tests)

| # | Nom test | Input | Output attendu | VÃ©rification |
|---|----------|-------|----------------|--------------|
| 1 | `test_rank_flights_by_price_sorts_ascending` | Liste 5 vols prix alÃ©atoires | Vols triÃ©s prix croissant | VÃ©rifier `results[i].price <= results[i+1].price` |
| 2 | `test_rank_flights_by_price_limits_to_10` | Liste 15 vols | Max 10 rÃ©sultats | VÃ©rifier `len(results) == 10` |
| 3 | `test_rank_flights_by_price_empty_list` | Liste vide `[]` | Liste vide retournÃ©e | VÃ©rifier `len(results) == 0` |

**Exemple code test AAA** :
```python
from app.services.ranking import rank_flights_by_price
from app.models.response import FlightResult

def test_rank_flights_by_price_sorts_ascending():
    # Arrange: Setup flights with random prices
    flights = [
        FlightResult(
            itinerary=["Paris", "Tokyo"],
            price=1500.00,
            currency="EUR",
            departure_date="2025-06-01",
            return_date="2025-06-15"
        ),
        FlightResult(
            itinerary=["Paris", "New York"],
            price=1200.00,
            currency="EUR",
            departure_date="2025-06-01",
            return_date="2025-06-15"
        ),
        FlightResult(
            itinerary=["Paris", "Tokyo", "New York"],
            price=1800.00,
            currency="EUR",
            departure_date="2025-06-01",
            return_date="2025-06-15"
        )
    ]

    # Act: Rank flights
    ranked = rank_flights_by_price(flights)

    # Assert: Verify ascending price order
    assert ranked[0].price == 1200.00
    assert ranked[1].price == 1500.00
    assert ranked[2].price == 1800.00

def test_rank_flights_by_price_limits_to_10():
    # Arrange: Setup 15 flights
    flights = [
        FlightResult(
            itinerary=["Paris", "Tokyo"],
            price=1000.00 + (i * 100),
            currency="EUR",
            departure_date="2025-06-01",
            return_date="2025-06-15"
        )
        for i in range(15)
    ]

    # Act: Rank flights
    ranked = rank_flights_by_price(flights)

    # Assert: Verify Top 10 limit
    assert len(ranked) == 10
```

**Total tests unitaires Ranking** : 3 tests

---

## Tests intÃ©gration

**Format recommandÃ© : Given/When/Then (BDD)**

**End-to-end** (4 tests) :

| # | ScÃ©nario | PrÃ©requis | Action | RÃ©sultat attendu |
|---|----------|-----------|--------|-------------------|
| 1 | `test_integration_multi_city_search_3_destinations` | Mocks configurÃ©s | POST /api/v1/search-flights avec 3 destinations | 200 + Top 10 rÃ©sultats triÃ©s prix |
| 2 | `test_integration_multi_city_crawls_parallel` | Logs activÃ©s | Recherche 3 destinations | Logs montrent crawls parallÃ¨les (timestamps simultanÃ©s) |
| 3 | `test_integration_multi_city_handles_partial_failures` | 2/6 crawls Ã©chouent | Recherche continue | Retourne rÃ©sultats disponibles (4/6) |
| 4 | `test_integration_multi_city_api_route` | App running | POST endpoint avec 3 destinations | 200 + SearchResponse JSON valide |

**Exemple code test Given/When/Then** :
```python
import pytest
from fastapi.testclient import TestClient
from unittest.mock import AsyncMock, MagicMock, patch
from app.main import app

client = TestClient(app)

def test_integration_multi_city_search_3_destinations():
    # Given: Application configured with mocked services
    with patch('app.services.crawler_service.AsyncWebCrawler') as mock_crawler, \
         patch('app.services.flight_parser.FlightParser') as mock_parser:

        mock_crawler_instance = AsyncMock()
        mock_crawler_instance.arun.return_value = MagicMock(
            html="<html>Mock flights</html>",
            success=True
        )
        mock_crawler.return_value = mock_crawler_instance

        mock_parser_instance = MagicMock()
        mock_parser_instance.parse_flights.return_value = [
            MagicMock(price=1200.00, itinerary=["Paris", "Tokyo"])
        ]
        mock_parser.return_value = mock_parser_instance

        request_data = {
            "destinations": ["Paris", "Tokyo", "New York"],
            "date_range": {
                "start": "2025-06-01",
                "end": "2025-06-15"
            }
        }

        # When: Client sends POST request
        response = client.post("/api/v1/search-flights", json=request_data)

        # Then: Response contains Top 10 sorted results
        assert response.status_code == 200
        data = response.json()
        assert "results" in data
        assert len(data["results"]) <= 10
        assert all(data["results"][i]["price"] <= data["results"][i+1]["price"] for i in range(len(data["results"])-1))

def test_integration_multi_city_handles_partial_failures():
    # Given: Application with partial crawl failures
    with patch('app.services.crawler_service.AsyncWebCrawler') as mock_crawler:
        mock_crawler_instance = AsyncMock()
        mock_crawler_instance.arun.side_effect = [
            MagicMock(html="<html>Success 1</html>", success=True),
            Exception("Timeout"),
            MagicMock(html="<html>Success 2</html>", success=True),
            Exception("Captcha detected")
        ]
        mock_crawler.return_value = mock_crawler_instance

        request_data = {
            "destinations": ["Paris", "Tokyo"],
            "date_range": {
                "start": "2025-06-01",
                "end": "2025-06-15"
            }
        }

        # When: Client sends request with partial failures
        response = client.post("/api/v1/search-flights", json=request_data)

        # Then: Response contains available results (no 500 error)
        assert response.status_code == 200
        data = response.json()
        assert "results" in data
```

**Total tests intÃ©gration** : 4 tests

---

## Fixtures PartagÃ©es

**tests/conftest.py** :
```python
import pytest
from unittest.mock import AsyncMock, MagicMock
from app.services.combination_generator import CombinationGenerator

@pytest.fixture
def mock_combination_generator():
    """Mock CombinationGenerator retournant 3 combinaisons prÃ©dÃ©finies."""
    generator = MagicMock(spec=CombinationGenerator)
    generator.generate_combinations.return_value = [
        ["Paris", "Tokyo", "Paris"],
        ["Paris", "New York", "Paris"],
        ["Paris", "Tokyo", "New York", "Paris"]
    ]
    return generator

@pytest.fixture
def mock_crawler_multiple_urls():
    """Mock CrawlerService retournant HTML diffÃ©rent par URL."""
    crawler = AsyncMock()
    crawler.crawl_google_flights.side_effect = [
        "<html>Flights Paris-Tokyo</html>",
        "<html>Flights Paris-NY</html>",
        "<html>Flights Paris-Tokyo-NY</html>"
    ]
    return crawler

@pytest.fixture
def mock_parser_multiple_flights():
    """Mock FlightParser retournant 3-5 FlightResult par HTML."""
    parser = MagicMock()
    parser.parse_flights.return_value = [
        MagicMock(price=1200.00),
        MagicMock(price=1350.00),
        MagicMock(price=1500.00)
    ]
    return parser
```

---

## Workflow TDD Story 5

**Phase 1 - TDD CombinationGenerator (6 tests)** :
1. Ã‰crire tests CombinationGenerator â†’ Tests Ã©chouent (red)
2. ImplÃ©menter `generate_combinations()` â†’ Tests passent (green)
3. Refactor si nÃ©cessaire

**Phase 2 - TDD SearchService Orchestration (8 tests)** :
1. Ã‰crire tests SearchService multi-city â†’ Tests Ã©chouent (red)
2. ImplÃ©menter orchestration (asyncio.gather, URL construction) â†’ Tests passent (green)
3. Refactor si nÃ©cessaire

**Phase 3 - TDD Ranking (3 tests)** :
1. Ã‰crire tests ranking â†’ Tests Ã©chouent (red)
2. ImplÃ©menter `rank_flights_by_price()` â†’ Tests passent (green)
3. Refactor si nÃ©cessaire

**Phase 4 - Tests IntÃ©gration (4 tests)** :
1. Ã‰crire tests end-to-end â†’ Tests Ã©chouent ou passent selon implÃ©mentation
2. VÃ©rifier workflow complet (request â†’ response)
3. Validation manuelle (curl)

**Total tests Story 5** : 21 tests (17 unitaires + 4 intÃ©gration), coverage â‰¥ 80%

---

# ğŸ“ Exemples JSON et DonnÃ©es

## Exemple 1: Request multi-city 3 destinations

```json
{
  "destinations": ["Paris", "Tokyo", "New York"],
  "date_range": {
    "start": "2025-06-01",
    "end": "2025-06-15"
  }
}
```

## Exemple 2: URL multi_city_json encodÃ©e

**Combinaison** : `["Paris", "Tokyo", "New York", "Paris"]`

**JSON segments** :
```json
[
  {
    "departure_id": "CDG",
    "arrival_id": "NRT",
    "date": "2025-06-01"
  },
  {
    "departure_id": "NRT",
    "arrival_id": "JFK",
    "date": "2025-06-08"
  },
  {
    "departure_id": "JFK",
    "arrival_id": "CDG",
    "date": "2025-06-15"
  }
]
```

**URL encodÃ©e** :
```
https://www.google.com/travel/flights?flight_type=3&multi_city_json=%5B%7B%22departure_id%22%3A%22CDG%22%2C%22arrival_id%22%3A%22NRT%22%2C%22date%22%3A%222025-06-01%22%7D%2C%7B%22departure_id%22%3A%22NRT%22%2C%22arrival_id%22%3A%22JFK%22%2C%22date%22%3A%222025-06-08%22%7D%2C%7B%22departure_id%22%3A%22JFK%22%2C%22arrival_id%22%3A%22CDG%22%2C%22date%22%3A%222025-06-15%22%7D%5D&hl=fr&curr=EUR
```

## Exemple 3: Combinaisons gÃ©nÃ©rÃ©es (6 pour 3 destinations)

**Input** :
```python
destinations = ["Paris", "Tokyo", "New York"]
```

**Output** :
```python
[
    ["Paris", "Tokyo", "Paris"],
    ["Paris", "New York", "Paris"],
    ["Paris", "Tokyo", "New York", "Paris"],
    ["Paris", "New York", "Tokyo", "Paris"],
    ["Tokyo", "Paris", "New York", "Tokyo"],
    ["New York", "Paris", "Tokyo", "New York"]
]
```

## Exemple 4: SearchResponse Top 10 multi-city

```json
{
  "results": [
    {
      "itinerary": ["Paris", "Tokyo", "Paris"],
      "price": 1150.00,
      "currency": "EUR",
      "departure_date": "2025-06-01",
      "return_date": "2025-06-15"
    },
    {
      "itinerary": ["Paris", "New York", "Paris"],
      "price": 1200.00,
      "currency": "EUR",
      "departure_date": "2025-06-01",
      "return_date": "2025-06-15"
    },
    {
      "itinerary": ["Paris", "Tokyo", "New York", "Paris"],
      "price": 1350.00,
      "currency": "EUR",
      "departure_date": "2025-06-01",
      "return_date": "2025-06-15"
    }
  ],
  "search_id": "b2c3d4e5-f6g7-4890-b123-456789abcdef",
  "total_results": 3
}
```

## Exemple 5: Response partielle (Ã©checs crawls)

**Contexte** : 6 combinaisons gÃ©nÃ©rÃ©es, 2 crawls Ã©chouent (captcha, timeout)

```json
{
  "results": [
    {
      "itinerary": ["Paris", "Tokyo", "Paris"],
      "price": 1200.00,
      "currency": "EUR",
      "departure_date": "2025-06-01",
      "return_date": "2025-06-15"
    },
    {
      "itinerary": ["Paris", "New York", "Paris"],
      "price": 1350.00,
      "currency": "EUR",
      "departure_date": "2025-06-01",
      "return_date": "2025-06-15"
    }
  ],
  "search_id": "c3d4e5f6-g7h8-4901-c234-567890abcdef",
  "total_results": 2
}
```

---

# ğŸ“Š Diagramme Workflow Multi-City

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. POST /api/v1/search-flights                                  â”‚
â”‚    {"destinations": ["Paris", "Tokyo", "New York"], ...}        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CombinationGenerator.generate_combinations()                 â”‚
â”‚    â†’ GÃ©nÃ¨re 6 combinaisons aller-retour                         â”‚
â”‚    [["Paris", "Tokyo", "Paris"], ...]                           â”‚
â”‚    Timing: <1ms                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. build_multi_city_url() pour chaque combinaison               â”‚
â”‚    â†’ 6 URLs multi_city_json encodÃ©es                            â”‚
â”‚    Timing: <10ms                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. asyncio.gather(*crawl_tasks, return_exceptions=True)         â”‚
â”‚    â†’ Crawl 6 URLs en parallÃ¨le                                  â”‚
â”‚    Timing: ~5-30s (timeout 30s/crawl)                           â”‚
â”‚                                                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚    â”‚Crawl 1 â”‚  â”‚Crawl 2 â”‚  â”‚Crawl 3 â”‚  â”‚Crawl 4 â”‚ ... (6x)    â”‚
â”‚    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â”‚
â”‚        â”‚           â”‚           â”‚           â”‚                    â”‚
â”‚    Success    Captcha âŒ   Success    Timeout âŒ               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚           â”‚           â”‚           â”‚
         â†“           â†“           â†“           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Filtrer Ã©checs + FlightParser.parse_flights()                â”‚
â”‚    â†’ 4/6 crawls success = 4 listes FlightResult                 â”‚
â”‚    Timing: ~100-500ms (parsing CSS)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. AgrÃ©gation rÃ©sultats multi-crawls                            â”‚
â”‚    â†’ Liste unique 12-20 FlightResult                            â”‚
â”‚    Timing: <10ms                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. rank_flights_by_price()                                      â”‚
â”‚    â†’ Tri prix croissant + limite Top 10                         â”‚
â”‚    Timing: <10ms                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. SearchResponse.create(results=top_10)                        â”‚
â”‚    â†’ 200 + JSON Top 10 rÃ©sultats                                â”‚
â”‚    Timing total: ~5-30s (dominÃ© par crawls)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Œ Points Ã©chec possibles (error handling) :
   - Crawl timeout (30s) â†’ Continue avec rÃ©sultats disponibles
   - Captcha detection â†’ Log WARNING + skip crawl
   - Parsing error â†’ Log ERROR + skip rÃ©sultat
   - Tous crawls Ã©chouent â†’ CrawlException levÃ©e (500)

â±ï¸ Timeouts par Ã©tape :
   - CombinationGenerator : <1ms
   - URL construction : <10ms
   - Crawls parallÃ¨les : 5-30s (max 30s/crawl)
   - Parsing : 100-500ms
   - Ranking : <10ms
   - Total : ~5-30s (3 destinations), ~30-90s (5+ destinations)
```

---

# âœ… CritÃ¨res d'acceptation

## CritÃ¨res fonctionnels (10)

1. **Combinaisons gÃ©nÃ©rÃ©es correctement** : `generate_combinations(["Paris", "Tokyo", "New York"])` retourne 6 combinaisons aller-retour
2. **Crawls parallÃ¨les exÃ©cutÃ©s** : `asyncio.gather()` exÃ©cute N crawls simultanÃ©ment (N = nb combinaisons)
3. **Top 10 rÃ©sultats triÃ©s prix** : SearchResponse.results contient â‰¤10 FlightResult triÃ©s prix croissant
4. **ItinÃ©raires multi-city cohÃ©rents** : 100% FlightResult.itinerary respectent combinaisons gÃ©nÃ©rÃ©es
5. **Dates utilisÃ©es correctement** : URLs multi-city utilisent `date_range.start` et `date_range.end` fournis
6. **Devise EUR fixe** : 100% FlightResult.currency == "EUR"
7. **Max 10 rÃ©sultats** : `len(SearchResponse.results) <= 10` mÃªme si 50+ rÃ©sultats agrÃ©gÃ©s
8. **Recherche 3 destinations < 30s** : p95 temps rÃ©ponse â‰¤ 30 secondes (6 crawls parallÃ¨les)
9. **Handling Ã©checs partiels** : Si 2/6 crawls Ã©chouent, retourne 4 rÃ©sultats disponibles (pas erreur 500)
10. **Validation Pydantic 2-10 destinations** : SearchRequest rejette < 2 destinations (status 422)

## CritÃ¨res techniques (9)

11. **Type hints PEP 695 strict** : CombinationGenerator, SearchService utilisent `list[str]`, `async def`, type hints complets
12. **asyncio.gather parallÃ©lisme** : Crawls exÃ©cutÃ©s en parallÃ¨le (vÃ©rifiable via logs timestamps simultanÃ©s)
13. **itertools.product combinaisons** : CombinationGenerator utilise `itertools.product()` ou pattern Ã©quivalent
14. **Dependency injection services** : SearchService reÃ§oit CombinationGenerator + CrawlerService + FlightParser via `__init__`
15. **URL encoding multi_city_json correct** : `urlencode()` appliquÃ© sur JSON segments, `%7B`, `%22` prÃ©sents dans URL
16. **Async def orchestration** : `SearchService.search_flights()` est async def avec await asyncio.gather
17. **Exceptions custom propagÃ©es** : CrawlException, CaptchaDetectedException propagÃ©es correctement depuis CrawlerService
18. **Pydantic validation active** : SearchRequest.destinations valide min_length=2 (dÃ©jÃ  implÃ©mentÃ© Story 3)
19. **Logging structurÃ© JSON** : Logs contiennent `nb_combinations`, `crawls_success`, `crawls_failed`, `top_10_price_range`

## CritÃ¨res qualitÃ© (8)

20. **Coverage â‰¥ 80%** : pytest --cov=app atteint 80%+ sur CombinationGenerator, SearchService, ranking modules
21. **21 tests passent** : 6 Generator + 8 Service + 3 Ranking + 4 intÃ©gration tous verts
22. **Mypy strict mode** : mypy app/ retourne 0 erreur de type
23. **Ruff lint/format** : ruff check . && ruff format . passent sans erreur
24. **Docstrings 1 ligne** : CombinationGenerator, SearchService, ranking helpers ont docstrings explicites
25. **Format tests AAA/Given-When-Then** : Tests unitaires AAA, tests intÃ©gration BDD respectÃ©s
26. **Fixtures pytest rÃ©utilisables** : `mock_combination_generator`, `mock_crawler_multiple_urls`, `mock_parser_multiple_flights` dÃ©finis
27. **CI/CD bloque si Ã©chec** : GitHub Actions exÃ©cute lint + format + typecheck + tests, bloque merge si Ã©chec

---

**Note importante** : Cette story (5 story points) complÃ¨te le MVP multi-destinations. Elle rÃ©utilise CrawlerService + FlightParser (Story 4) sans modification, applique orchestration asyncio.gather pour performance, et implÃ©mente ranking Top 10 global. Les optimisations (caching combinaisons, retry logic, rate limiting) sont reportÃ©es Phase 6+.

**DÃ©pendances Story 4 rÃ©utilisÃ©es** :
- `CrawlerService.crawl_google_flights(url)` â†’ Aucun changement
- `FlightParser.parse_flights(html, destinations)` â†’ Aucun changement
- `CaptchaDetectedException`, `CrawlException` â†’ PropagÃ©es directement

**Principe SMART** : Chaque critÃ¨re est **S**pÃ©cifique (cible claire), **M**esurable (tests automatisÃ©s + mÃ©triques temps rÃ©ponse), **A**tteignable (scope MVP multi-city), **R**elevant (valeur business feature signature), **T**emporel (Phase 4.6).

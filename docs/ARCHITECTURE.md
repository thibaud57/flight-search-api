---
title: "ARCHITECTURE ‚Äî Vision d'ensemble"
description: "Architecture globale, diagrammes (composants, s√©quence), ADRs (6 d√©cisions techniques). Consulter pour comprendre structure API async, flow de donn√©es, d√©cisions architecturales (Crawl4AI vs SerpAPI, proxies, captcha, extraction CSS)."
date: "2025-11-16"
keywords: ["architecture", "design", "adr", "architecture-decision-record", "diagrams", "mermaid", "fastapi", "async", "crawl4ai", "proxies", "decodo", "scraping", "api", "flow", "components"]
scope: ["docs", "code"]
technologies: ["python", "fastapi", "crawl4ai", "pydantic", "tenacity"]
---

# üß≠ Contexte Projet

## Objectif

Fournir une API RESTful asynchrone permettant de rechercher les meilleures combinaisons de vols multi-destinations en scrapant Google Flights, avec gestion intelligente des proxies, d√©tection de captchas et ranking des r√©sultats.

## Type de Projet

**API RESTful Async** : Service backend stateless de scraping web intelligent avec anti-d√©tection (proxies r√©sidentiels + stealth mode).

## Enjeux & Contraintes

- **Co√ªts** : Optimiser co√ªts proxies (<50‚Ç¨/mois) et √©viter co√ªts API LLM
- **Rate Limits** : G√©rer limites Google Flights via rotation proxies et retry intelligent
- **Anti-D√©tection** : √âviter blocages Google (stealth mode + proxies r√©sidentiels France)
- **Performance** : Temps r√©ponse <60s pour recherches multi-city complexes
- **Scalabilit√©** : Architecture stateless pour scaling horizontal facile
- **Maintenance** : Minimiser d√©pendance structure HTML Google (monitoring parsing failures)

## Public Cible

- **n8n workflows** : Automation tools cherchant int√©gration API vols
- **D√©veloppeurs** : Cherchant alternative low-cost √† SerpAPI
- **Internes** : MVP proof-of-concept scraping intelligent

---

# üèóÔ∏è Architecture Globale

## Architecture ‚Äî Approche G√©n√©rale

**Stateless API Async-First** : Monolithe modulaire avec service layer, sans base de donn√©es (Top 10 r√©sultats en m√©moire).

## Principes Architecturaux

1. **Async-First** : Architecture 100% asynchrone (FastAPI + AsyncWebCrawler)
2. **Stateless** : Pas de base de donn√©es, r√©sultats en m√©moire (Top 10)
3. **Resilient** : Retry logic avec exponential backoff + jitter
4. **Stealth** : Anti-d√©tection via proxies r√©sidentiels + undetected browser
5. **Cost-Efficient** : Extraction CSS (gratuit) vs LLM (payant)

## Composants Principaux (Haut Niveau)

- **Frontend** : Aucun (API backend uniquement)
- **Backend** : FastAPI async avec routes REST + Pydantic validation
- **Donn√©es** : Stateless (Top 10 en m√©moire, pas de DB)
- **Processing** : AsyncWebCrawler parall√®le + parsing CSS
- **S√©curit√©** : Proxies r√©sidentiels anti-d√©tection + secrets .env
- **Int√©grations Externes** : Decodo Proxies, Crawl4AI, Google Flights

## Patterns Utilis√©s

- **Async/Await** : Crawling parall√®le, I/O non-bloquant
- **Retry Pattern** : Tenacity avec exponential backoff + jitter
- **Service Layer** : S√©paration logique business (SearchService, CrawlerService, ProxyService)
- **Dependency Injection** : FastAPI DI pour Config, Logger
- **Strategy Pattern** : Rotation proxies (round-robin)

## Diagramme de Composants

```mermaid
graph TB
    subgraph "Client Layer"
        Client[Client HTTP/n8n]
    end

    subgraph "API Layer"
        FastAPI[FastAPI App]
        Router[API Router]
        Validator[Pydantic Validator]
    end

    subgraph "Core Layer"
        Config[Config Manager]
        Logger[Structured Logger]
    end

    subgraph "Service Layer"
        SearchService[Search Service]
        CombinationGen[Combination Generator]
        CrawlerService[Crawler Service]
        ProxyService[Proxy Service]
        FlightParser[Flight Parser Service]
    end

    subgraph "External Dependencies"
        Crawl4AI[Crawl4AI + Playwright]
        Decodo[Decodo Proxies]
        GoogleFlights[Google Flights]
    end

    Client -->|POST /api/v1/search-flights| FastAPI
    FastAPI --> Router
    Router --> Validator
    Validator --> SearchService

    SearchService --> CombinationGen
    SearchService --> CrawlerService
    SearchService --> FlightParser

    CrawlerService --> ProxyService
    CrawlerService --> Crawl4AI
    ProxyService --> Decodo
    Crawl4AI -->|HTTP Request via Proxy| GoogleFlights

    SearchService --> Logger
    CrawlerService --> Logger

    Config -.->|Settings| SearchService
    Config -.->|Settings| CrawlerService
    Config -.->|Settings| ProxyService
```

---

# üåê Architecture Technique

## üíª Backend

### Runtime & Langage

**Python 3.13** : Version moderne avec meilleures performances async et type hints (PEP 695).

### Framework

**FastAPI 0.121+** : Framework async moderne avec validation Pydantic v2, auto-documentation OpenAPI, et performances √©lev√©es.

### Structure du Code

**Service Layer Pattern** : S√©paration claire responsabilit√©s (API routes ‚Üí Services ‚Üí External APIs).

```
app/
‚îú‚îÄ‚îÄ api/routes.py          # Routes FastAPI
‚îú‚îÄ‚îÄ core/                  # Config + Logger
‚îú‚îÄ‚îÄ models/                # Pydantic models (request/response)
‚îú‚îÄ‚îÄ services/              # Business logic
‚îÇ   ‚îú‚îÄ‚îÄ search_service.py
‚îÇ   ‚îú‚îÄ‚îÄ crawler_service.py
‚îÇ   ‚îú‚îÄ‚îÄ proxy_service.py
‚îÇ   ‚îî‚îÄ‚îÄ flight_parser.py
‚îî‚îÄ‚îÄ utils/                 # Helpers
```

### API

**REST** : Endpoints RESTful avec validation Pydantic stricte, responses JSON structur√©es.

- `POST /api/v1/search-flights` : Recherche vols multi-city
- `GET /health` : Health check production

### Services Externes

- **Decodo Proxies** : Proxies r√©sidentiels France (anti-d√©tection)
- **Crawl4AI** : AsyncWebCrawler + Playwright int√©gr√© (scraping stealth)
- **Google Flights** : Source donn√©es vols (scraping HTML)

## üóÑÔ∏è Donn√©es (Base de Donn√©es)

### Approche

**Stateless - Top 10 en M√©moire** : Pas de base de donn√©es, r√©sultats tri√©s par prix et limit√©s √† Top 10 en m√©moire (voir [ADR #003](./adrs/003-top10-memory-vs-db.md)).

**Justification** :
- Use case API stateless pour n8n ‚Üí pas besoin persistance
- Performance optimale (pas d'I/O DB)
- Co√ªts $0 (pas d'h√©bergement DB)

### Extensions Futures Possibles

- **Redis Cache** : TTL 15min pour r√©sultats identiques (optimisation co√ªts proxies)
- **PostgreSQL Analytics** : Historique recherches, tendances prix (Phase 8+)

## üóÉÔ∏è Donn√©es & Cache

### Cache

**Aucun (MVP)** : Pas de cache Redis pour MVP. Chaque recherche = crawling fresh data.

**Extensions possibles** :
- Redis avec TTL 15min pour m√™me recherche (√©conomie bandwidth)
- Cache r√©sultats identiques (m√™me origine/destination/dates)

---

# üîÑ Flow de Donn√©es & S√©quence

## Diagramme de S√©quence - Recherche de Vol

```mermaid
sequenceDiagram
    participant Client
    participant FastAPI
    participant SearchService
    participant CombinationGen
    participant CrawlerService
    participant ProxyService
    participant Crawl4AI
    participant GoogleFlights
    participant FlightParser

    Client->>FastAPI: POST /api/v1/search-flights
    FastAPI->>FastAPI: Validate Request (Pydantic)
    FastAPI->>SearchService: search_flights(request)

    SearchService->>CombinationGen: generate_combinations(destinations, dates)
    CombinationGen-->>SearchService: List[Combination]

    loop Pour chaque combinaison
        SearchService->>CrawlerService: crawl_google_flights(combination)
        CrawlerService->>ProxyService: get_next_proxy()
        ProxyService-->>CrawlerService: ProxyConfig

        CrawlerService->>Crawl4AI: arun(url, proxy_config)
        Crawl4AI->>GoogleFlights: HTTP GET (via proxy)

        alt Success
            GoogleFlights-->>Crawl4AI: HTML Response
            Crawl4AI-->>CrawlerService: CrawlResult
            CrawlerService->>CrawlerService: Check Captcha Detection

            alt No Captcha
                CrawlerService-->>SearchService: HTML
                SearchService->>FlightParser: parse_flights(html)
                FlightParser-->>SearchService: List[FlightResult]
            else Captcha Detected
                CrawlerService->>CrawlerService: Log Warning
                CrawlerService->>ProxyService: rotate_proxy()
                CrawlerService->>CrawlerService: Retry with tenacity
            end
        else Network Error
            Crawl4AI-->>CrawlerService: Exception
            CrawlerService->>CrawlerService: Retry with tenacity
        end
    end

    SearchService->>SearchService: Rank & Select Top 10
    SearchService-->>FastAPI: SearchResponse (Top 10)
    FastAPI-->>Client: JSON Response
```

## Flow de Donn√©es D√©taill√©

### √âtape 1 : R√©ception & Validation

```
Client ‚Üí POST /api/v1/search-flights
Body: {
  "destinations": ["Paris", "Tokyo", "New York"],
  "date_range": {
    "start": "2025-06-01",
    "end": "2025-06-15"
  }
}
‚Üì
Pydantic Validation:
- V√©rification format dates
- Validation destinations (non vides)
- Contraintes m√©tier (max 5 destinations, etc.)
```

### √âtape 2 : G√©n√©ration Combinaisons

```
CombinationGenerator
‚Üì
G√©n√®re toutes les permutations multi-city possibles:
- Paris ‚Üí Tokyo ‚Üí New York
- Paris ‚Üí New York ‚Üí Tokyo
- Tokyo ‚Üí Paris ‚Üí New York
- ...
‚Üì
Output: List[Combination] (N! combinaisons)
```

### √âtape 3 : Crawling Parall√®le

```
Pour chaque combinaison:
  ‚Üì
  ProxyService.get_next_proxy()
  ‚Üí Rotation round-robin des proxies Decodo
  ‚Üì
  CrawlerService.crawl()
  ‚Üí AsyncWebCrawler avec:
    - Undetected browser mode
    - Proxy Decodo (residential, France)
    - Stealth mode activ√©
  ‚Üì
  Crawl4AI ‚Üí Google Flights
  ‚Üí Requ√™te HTTP via proxy
  ‚Üì
  D√©tection Captcha:
    - Si captcha d√©tect√© ‚Üí Log + Retry avec nouveau proxy
    - Sinon ‚Üí Continue
  ‚Üì
  Return HTML brut
```

### √âtape 4 : Parsing & Extraction

```
FlightParser.parse_flights(html)
‚Üì
JsonCssExtractionStrategy:
- S√©lecteurs CSS pour prix, horaires, compagnies
- Extraction structur√©e (pas de LLM)
‚Üì
Output: List[FlightResult] par combinaison
```

### √âtape 5 : Ranking & S√©lection

```
SearchService.rank_results()
‚Üì
Crit√®res de ranking:
- Prix total (poids principal)
- Dur√©e totale trajet
- Nombre d'escales
- Compagnie a√©rienne
‚Üì
S√©lection Top 10 r√©sultats
```

### √âtape 6 : Response

```json
SearchResponse:
{
  "results": [
    {
      "combination": ["Paris", "Tokyo", "New York"],
      "total_price": 1250.00,
      "currency": "EUR",
      "flights": [
        {
          "from": "Paris",
          "to": "Tokyo",
          "departure": "2025-06-01T10:30:00",
          "arrival": "2025-06-02T06:45:00",
          "price": 650.00,
          "airline": "Air France"
        },
        ...
      ]
    },
    ...
  ],
  "stats": {
    "total_combinations_checked": 120,
    "successful_crawls": 115,
    "captcha_detected": 5,
    "execution_time_seconds": 45.2
  }
}
```

---

# üõ†Ô∏è Infrastructure, S√©curit√© & Observabilit√©

## üöÄ Infrastructure

### H√©bergement

**Dokploy (VPS)** : D√©ploiement Docker sur VPS avec UI Dokploy pour gestion secrets et monitoring.

### Conteneurisation

**Docker multi-stage** : Optimis√© pour production (builder + runtime s√©par√©s), non-root user, healthcheck natif.

**Justification** :
- R√©duction taille image (~60% via multi-stage)
- S√©curit√© (non-root user)
- Monitoring int√©gr√© (healthcheck)

> **D√©tails impl√©mentation** : Voir [CODING_STANDARDS.md ¬ß5 Docker](CODING_STANDARDS.md#-5-docker--containers) pour Dockerfile complet, commandes, et best practices.

### CI/CD

**GitHub Actions** :
- `.github/workflows/ci.yml` : Quality checks (ruff, mypy, pytest, coverage)
- `.github/workflows/release.yml` : Auto-release sur tags `v*`

### Environnements

- **Dev** : Local (`fastapi dev app/main.py`)
- **Production** : Dokploy VPS (Docker container)

### S√©curit√© Infrastructure

- **Secrets** : `.env` local, Dokploy UI production (jamais commit `.env`)
- **Non-root user** : Docker container run as `nobody`
- **Network** : Proxies Decodo (IP rotation anti-ban)

### Scalabilit√© & Performance

- **Scalabilit√©** : Stateless ‚Üí scaling horizontal trivial (add containers)
- **Load balancing** : Non n√©cessaire MVP (single container suffisant)
- **Auto-scaling** : Non n√©cessaire MVP
- **Optimisation** : Async I/O, crawling parall√®le, bandwidth optimis√© (ADR #006)

## üîê S√©curit√© Globale

### Strat√©gie S√©curit√©

**OWASP Top 10** : Validation Pydantic stricte, secrets env vars, rate limiting possible Phase 7+.

### Authentification

**Aucune (MVP)** : API publique pour MVP. Extensions possibles : API keys, JWT.

### Autorisation

**Aucune (MVP)** : Pas de RBAC n√©cessaire pour MVP.

### Protection API

- **Rate Limit** : Non impl√©ment√© MVP (possible Phase 7+ si abuse)
- **CORS** : Configur√© FastAPI si besoin frontend
- **Validation** : Pydantic strict sur tous endpoints

### Protection Donn√©es

- **Secrets** : `.env` (local) + Dokploy UI (production)
- **Chiffrement** : HTTPS via Dokploy reverse proxy
- **Rotation** : Pas de cl√©s √† rotationner MVP (proxies Decodo fixes)

## üìä Observabilit√©

### Logs

**Structured JSON Logging** (`python-json-logger`) : Format JSON avec contexte m√©tier riche (search_id, destinations, proxy_used, captcha_detected, etc.).

**Justification** :
- Machine-readable pour parsing Grafana/Loki
- Contexte m√©tier actionable pour debugging
- Compatible stacks observabilit√© modernes

**Stack** : stdout ‚Üí Dokploy UI logs (visualisation temps r√©el).

> **D√©tails impl√©mentation** : Voir [CODING_STANDARDS.md ¬ß2.3 Structured Logging](CODING_STANDARDS.md#23-structured-logging) pour configuration logger, exemples complets, et r√®gles masquage secrets.

### Monitoring

**M√©triques Cl√©s** :

| M√©trique | Seuil Alerte | Action |
|----------|--------------|--------|
| **Taux captcha** | >5% | √âvaluer int√©gration 2Captcha (Phase 7) |
| **Parsing failures** | >5% | V√©rifier s√©lecteurs CSS |
| **Proxy bandwidth** | >50GB/mois | Optimiser requ√™tes |
| **Response time p95** | >60s | Optimiser parall√©lisation |

### Alerts

**MVP** : Monitoring manuel logs Dokploy UI. Extensions Phase 7+ : Grafana/Loki, webhooks alerting.

## üß™ Tests

### Strat√©gie de Tests

- **Tests unitaires** : Services isol√©s avec mocks (Crawl4AI, Decodo, HTML)
- **Tests int√©gration** : FastAPI TestClient (routes end-to-end)
- **Tests e2e** : Manuels (vraies URLs Google Flights, vraies cl√©s Decodo)
- **Coverage** : Minimum 80% (CI bloque si inf√©rieur)

### Tools

- **pytest** : Framework tests async
- **pytest-asyncio** : Support async tests
- **pytest-cov** : Coverage reporting
- **Fixtures** : `tests/fixtures/` (DRY principe)

### Configuration

**Pytest** : Configuration compl√®te dans `pyproject.toml` (testpaths, asyncio auto, coverage 80% minimum).

> **D√©tails configuration** : Voir [CODING_STANDARDS.md ¬ß3.4 Configuration Pytest](CODING_STANDARDS.md#34-configuration-pytest) pour configuration compl√®te, commandes, et patterns de tests.

---

# üìù ADRs & D√©cisions

## Index ADRs

- **[ADR #001](./adrs/001-crawl4ai-vs-serpapi.md)** : Crawl4AI + Proxies vs SerpAPI
- **[ADR #002](./adrs/002-decodo-vs-oxylabs.md)** : Decodo vs Oxylabs (Proxies R√©sidentiels)
- **[ADR #003](./adrs/003-top10-memory-vs-db.md)** : Top 10 en M√©moire vs Base de Donn√©es
- **[ADR #004](./adrs/004-tenacity-retry.md)** : Tenacity pour Retry Logic
- **[ADR #005](./adrs/005-captcha-detection-mvp.md)** : Captcha Handling Strategy (MVP : D√©tection Only)
- **[ADR #006](./adrs/006-css-vs-llm-extraction.md)** : JsonCssExtractionStrategy vs LLMExtractionStrategy

## D√©cisions Compl√©mentaires

### Logging Structur√© (JSON)

**D√©cision** : Utiliser `python-json-logger` pour logs structur√©s

**Justification** :
- Machine-readable (parsing facile pour Grafana/Loki)
- Contexte m√©tier riche (search_id, proxy_used, captcha_detected)
- Compatible stacks observabilit√© modernes (CloudWatch, Loki, Datadog)

### Configuration (Pydantic Settings)

**D√©cision** : `pydantic-settings` pour env vars

**Justification** :
- Validation automatique types (.env ‚Üí Python types)
- Type safety (mypy strict compatible)
- Auto-documentation (`.env.example` g√©n√©r√©)
- DX excellent (autocomplete IDE)

---

# üöÄ √âvolutions Futures

## Phase 7 (Post-MVP) : Captcha Solving

**Trigger** : Monitoring montre >5% taux captcha persistant

**Solutions** :
1. Int√©gration 2Captcha (r√©solution auto)
2. Optimisation proxies (pools d√©di√©s moins utilis√©s)
3. Rate limiting intelligent (throttling requests)

**Co√ªt estim√©** : +$10-50/mois selon volume captchas

## Extensions Possibles

- **Cache Redis** : R√©sultats temporaires (15min TTL) ‚Üí √©conomie bandwidth proxies
- **Analytics DB** : PostgreSQL pour historique recherches, tendances prix
- **LLM Fallback** : Si Google change drastiquement HTML (voir ADR #006)
- **Webhooks** : Notifications async recherches termin√©es
- **Multi-Currency** : Support USD, GBP, JPY (actuellement EUR uniquement)
- **API Keys** : Authentification simple via header `X-API-Key`
- **Rate Limiting** : Protection abuse (ex: 100 req/hour par IP)

---

# üîó Ressources

## Documentation Officielle

- **Mermaid Diagrams** : https://mermaid.js.org/
- **C4 Model** : https://c4model.com/
- **FastAPI** : https://fastapi.tiangolo.com/
- **Crawl4AI** : https://docs.crawl4ai.com/
- **Pydantic v2** : https://docs.pydantic.dev/latest/

## Ressources Compl√©mentaires

- **ADR GitHub** : https://adr.github.io/
- **Architecture Decision Records** : https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions
- **Decodo Proxies** : https://help.decodo.com/docs/introduction
- **Tenacity** : https://tenacity.readthedocs.io/
